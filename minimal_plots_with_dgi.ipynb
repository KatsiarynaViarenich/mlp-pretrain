{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "from ogb.nodeproppred import Evaluator, PygNodePropPredDataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch.nn import Linear\n",
    "from typing import Tuple, Union\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.typing import Adj, OptPairTensor, Size\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from torch_geometric.nn.models import DeepGraphInfomax"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mkats\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "Widget Javascript not detected.  It may not be installed or enabled properly. Reconnecting the current kernel may help.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d17930bf9141fb9af58b1814513a4d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>./wandb/wandb/run-20230421_131221-b244ylud</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/kats/pretrain-mlpinit/runs/b244ylud' target=\"_blank\">pleasant-snow-6</a></strong> to <a href='https://wandb.ai/kats/pretrain-mlpinit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/kats/pretrain-mlpinit' target=\"_blank\">https://wandb.ai/kats/pretrain-mlpinit</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/kats/pretrain-mlpinit/runs/b244ylud' target=\"_blank\">https://wandb.ai/kats/pretrain-mlpinit/runs/b244ylud</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/kats/pretrain-mlpinit/runs/b244ylud?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x7fdadab3c640>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project = \"pretrain-mlpinit\",\n",
    "    dir = \"./wandb\",\n",
    "    config = {\n",
    "        \"init_method\": \"mlp\",\n",
    "        \"dataset_name\": \"ogbn-arxiv\",\n",
    "        \"batch_size\": 1024,\n",
    "        \"num_layers\": 4,\n",
    "        \"hidden_channels\": 512\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.x.shape: torch.Size([169343, 128])\n",
      "data.y.shape: torch.Size([169343, 1])\n",
      "data.x.type: torch.float32\n",
      "data.y.type: torch.int64\n",
      "x_train.shape: torch.Size([90941, 128])\n",
      "y_train.shape: torch.Size([90941])\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"./data\"\n",
    "num_workers = 4\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "root = osp.join(dataset_dir, wandb.config.dataset_name)\n",
    "\n",
    "dataset = PygNodePropPredDataset(wandb.config.dataset_name, root)\n",
    "split_idx = dataset.get_idx_split()\n",
    "evaluator = Evaluator(name=wandb.config.dataset_name)\n",
    "data = dataset[0]\n",
    "train_idx = split_idx[\"train\"]\n",
    "\n",
    "x_train = data.x[split_idx[\"train\"]]\n",
    "y_train = data.y[split_idx[\"train\"]].reshape(-1).type(torch.long)\n",
    "\n",
    "\n",
    "x = data.x\n",
    "y = data.y.squeeze()\n",
    "\n",
    "\n",
    "print(\"data.x.shape:\", data.x.shape)\n",
    "print(\"data.y.shape:\", data.y.shape)\n",
    "print(\"data.x.type:\", x.dtype)\n",
    "print(\"data.y.type:\", y.dtype)\n",
    "print(\"x_train.shape:\", x_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "\n",
    "\n",
    "y = data.y.squeeze().type(torch.long)\n",
    "\n",
    "\n",
    "x_y_train_mlpinit = data_utils.TensorDataset(x_train, y_train)\n",
    "x_y_all_mlpinit = data_utils.TensorDataset(x, y)\n",
    "\n",
    "train_mlpinit_loader = data_utils.DataLoader(\n",
    "    x_y_train_mlpinit,\n",
    "    batch_size=wandb.config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "all_mlpinit_loader = data_utils.DataLoader(\n",
    "    x_y_all_mlpinit,\n",
    "    batch_size=wandb.config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "\n",
    "class SAGEConv_PeerMLP(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A PyTorch module implementing a simplified GraphSAGE convolution-like multilayer perceptron (MLP) layer.\n",
    "\n",
    "    This layer performs a linear transformation on the input node features, optionally normalizing\n",
    "    the output and adding a root weight.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: Union[int, Tuple[int, int]],\n",
    "        out_channels: int,\n",
    "        normalize: bool = False,\n",
    "        root_weight: bool = True,\n",
    "        bias: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "        self.root_weight = root_weight\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "\n",
    "        self.lin_l = Linear(in_channels[0], out_channels, bias=bias)\n",
    "        if self.root_weight:\n",
    "            self.lin_r = Linear(in_channels[1], out_channels, bias=False)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_l.reset_parameters()\n",
    "        if self.root_weight:\n",
    "            self.lin_r.reset_parameters()\n",
    "\n",
    "    def forward(self, x: Union[Tensor, OptPairTensor]) -> Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        if isinstance(x, Tensor):\n",
    "            x: OptPairTensor = (x, x)\n",
    "\n",
    "        out = x[1]\n",
    "        out = self.lin_l(out)\n",
    "\n",
    "        x_r = x[1]\n",
    "        if self.root_weight and x_r is not None:\n",
    "            out += self.lin_r(x_r)\n",
    "\n",
    "        if self.normalize:\n",
    "            out = F.normalize(out, p=2.0, dim=-1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv_PeerMLP(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv_PeerMLP(hidden_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConv_PeerMLP(hidden_channels, out_channels))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.num_layers):\n",
    "            x_target = x\n",
    "            x = self.convs[i]((x, x_target))\n",
    "            if i != self.num_layers - 1:\n",
    "                x = F.relu(x)\n",
    "        return x.log_softmax(dim=-1)\n",
    "\n",
    "\n",
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adjs):\n",
    "        # `train_loader` computes the k-hop neighborhood of a batch of nodes,\n",
    "        # and returns, for each layer, a bipartite graph object, holding the\n",
    "        # bipartite edges `edge_index`, the index `e_id` of the original edges,\n",
    "        # and the size/shape `size` of the bipartite graph.\n",
    "        # Target nodes are also included in the source nodes so that one can\n",
    "        # easily apply skip-connections or add self-loops.\n",
    "        for i, (edge_index, _, size) in enumerate(adjs):\n",
    "            x_target = x[: size[1]]  # Target nodes are always placed first.\n",
    "            x = self.convs[i]((x, x_target), edge_index)\n",
    "            if i != self.num_layers - 1:\n",
    "                x = F.relu(x)\n",
    "        return x.log_softmax(dim=-1)\n",
    "\n",
    "    def inference(self, x_all):\n",
    "        pbar = tqdm(total=x_all.size(0) * self.num_layers)\n",
    "        pbar.set_description(\"Evaluating\")\n",
    "\n",
    "        # Compute representations of nodes layer by layer, using *all*\n",
    "        # available edges. This leads to faster computation in contrast to\n",
    "        # immediately computing the final representations of each batch.\n",
    "        total_edges = 0\n",
    "        for i in range(self.num_layers):\n",
    "            xs = []\n",
    "            for batch_size, n_id, adj in subgraph_loader:\n",
    "                edge_index, _, size = adj.to(device)\n",
    "                total_edges += edge_index.size(1)\n",
    "                x = x_all[n_id].to(device)\n",
    "                x_target = x[: size[1]]\n",
    "                x = self.convs[i]((x, x_target), edge_index)\n",
    "                if i != self.num_layers - 1:\n",
    "                    x = F.relu(x)\n",
    "                xs.append(x.cpu())\n",
    "\n",
    "                pbar.update(batch_size)\n",
    "\n",
    "            x_all = torch.cat(xs, dim=0)\n",
    "\n",
    "        pbar.close()\n",
    "\n",
    "        return x_all\n",
    "\n",
    "\n",
    "model_mlpinit = MLP(\n",
    "    in_channels=dataset.num_features,\n",
    "    hidden_channels=wandb.config.hidden_channels,\n",
    "    out_channels=dataset.num_classes,\n",
    "    num_layers=wandb.config.num_layers,\n",
    ")\n",
    "model_mlpinit = model_mlpinit.to(device)\n",
    "optimizer_model_mlpinit = torch.optim.Adam(model_mlpinit.parameters(), lr=0.001, weight_decay=0.0)\n",
    "\n",
    "## теперь нужно посмотреть, тренируется ли эта модель и как. найти где можно организовать графики\n",
    "## найти как они измеряют и запустить тупо на всём датасете\n",
    "## всунуть дги везде где можно чтобы проверить на всем чем можно\n",
    "\n",
    "def train_mlpinit():\n",
    "    def index_corruption(x):\n",
    "        mask = torch.ones(x.size()[0], 128)\n",
    "        mask[:][torch.randperm(128)[:32]] = 0\n",
    "        mask = mask.to(device)\n",
    "        x = torch.where(mask.bool(), x, torch.zeros_like(x))\n",
    "        return x\n",
    "\n",
    "    def dropout_corruption(x):\n",
    "        pass\n",
    "\n",
    "    def summary(z, *args, **kwargs):\n",
    "        return torch.sigmoid(z.mean(dim=0))\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    unsupervised_model = DeepGraphInfomax(hidden_channels=40, encoder=model_mlpinit, summary=summary, corruption=index_corruption)\n",
    "    unsupervised_model.train()\n",
    "    for x, _ in tqdm(train_mlpinit_loader):\n",
    "        x = x.to(device)\n",
    "\n",
    "        optimizer_model_mlpinit.zero_grad()\n",
    "        pos_z, neg_z, summary = unsupervised_model(x)\n",
    "        loss = unsupervised_model.loss(pos_z, neg_z, summary)\n",
    "        loss.backward()\n",
    "        optimizer_model_mlpinit.step()\n",
    "\n",
    "        total_loss += float(loss)\n",
    "\n",
    "    loss = total_loss / len(train_mlpinit_loader)\n",
    "    unsupervised_model.eval()\n",
    "    return loss, 0\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_mlpinit():\n",
    "    model_mlpinit.eval()\n",
    "\n",
    "    out_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for x, y in tqdm(all_mlpinit_loader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        out = model_mlpinit(x)\n",
    "        out_list.append(out)\n",
    "        y_list.append(y)\n",
    "\n",
    "    out = torch.cat(out_list, dim=0)\n",
    "    y_true = torch.cat(y_list, dim=0).cpu().unsqueeze(-1)\n",
    "\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval(\n",
    "        {\n",
    "            \"y_true\": y_true[split_idx[\"train\"]],\n",
    "            \"y_pred\": y_pred[split_idx[\"train\"]],\n",
    "        }\n",
    "    )[\"acc\"]\n",
    "    val_acc = evaluator.eval(\n",
    "        {\n",
    "            \"y_true\": y_true[split_idx[\"valid\"]],\n",
    "            \"y_pred\": y_pred[split_idx[\"valid\"]],\n",
    "        }\n",
    "    )[\"acc\"]\n",
    "    test_acc = evaluator.eval(\n",
    "        {\n",
    "            \"y_true\": y_true[split_idx[\"test\"]],\n",
    "            \"y_pred\": y_pred[split_idx[\"test\"]],\n",
    "        }\n",
    "    )[\"acc\"]\n",
    "\n",
    "    return train_acc, val_acc, test_acc\n",
    "\n",
    "\n",
    "train_loader = NeighborSampler(\n",
    "    data.edge_index,\n",
    "    node_idx=train_idx,\n",
    "    sizes=[25, 10, 5, 5],\n",
    "    batch_size=wandb.config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "subgraph_loader = NeighborSampler(\n",
    "    data.edge_index,\n",
    "    node_idx=None,\n",
    "    sizes=[-1],\n",
    "    batch_size=wandb.config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "\n",
    "model = SAGE(\n",
    "    in_channels=dataset.num_features,\n",
    "    hidden_channels=wandb.config.hidden_channels,\n",
    "    out_channels=dataset.num_classes,\n",
    "    num_layers=wandb.config.num_layers,\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(total=train_idx.size(0))\n",
    "    pbar.set_description(f\"Epoch {epoch:02d}\")\n",
    "\n",
    "    total_loss = total_correct = 0\n",
    "\n",
    "    for batch_size, n_id, adjs in train_loader:\n",
    "        # `adjs` holds a list of `(edge_index, e_id, size)` tuples.\n",
    "        adjs = [adj.to(device) for adj in adjs]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(x[n_id].to(device), adjs)\n",
    "        loss = F.nll_loss(out, y[n_id[:batch_size]].to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss)\n",
    "        total_correct += int(out.argmax(dim=-1).eq(y[n_id[:batch_size]].to(device)).sum())\n",
    "        pbar.update(batch_size)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    loss = total_loss / len(train_loader)\n",
    "    approx_acc = total_correct / train_idx.size(0)\n",
    "\n",
    "    return loss, approx_acc\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    out = model.inference(x)\n",
    "\n",
    "    y_true = y.cpu().unsqueeze(-1)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval(\n",
    "        {\n",
    "            \"y_true\": y_true[split_idx[\"train\"]],\n",
    "            \"y_pred\": y_pred[split_idx[\"train\"]],\n",
    "        }\n",
    "    )[\"acc\"]\n",
    "    val_acc = evaluator.eval(\n",
    "        {\n",
    "            \"y_true\": y_true[split_idx[\"valid\"]],\n",
    "            \"y_pred\": y_pred[split_idx[\"valid\"]],\n",
    "        }\n",
    "    )[\"acc\"]\n",
    "    test_acc = evaluator.eval(\n",
    "        {\n",
    "            \"y_true\": y_true[split_idx[\"test\"]],\n",
    "            \"y_pred\": y_pred[split_idx[\"test\"]],\n",
    "        }\n",
    "    )[\"acc\"]\n",
    "\n",
    "    return train_acc, val_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01: 100%|██████████| 90941/90941 [02:12<00:00, 685.21it/s]\n",
      "Evaluating: 100%|██████████| 677372/677372 [00:20<00:00, 32307.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, Train: 0.5160, Val: 0.5134, Test: 0.4560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02: 100%|██████████| 90941/90941 [02:28<00:00, 612.90it/s]\n",
      "Evaluating: 100%|██████████| 677372/677372 [00:29<00:00, 23066.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02, Train: 0.5735, Val: 0.5642, Test: 0.5121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03: 100%|██████████| 90941/90941 [02:14<00:00, 674.50it/s]\n",
      "Evaluating: 100%|██████████| 677372/677372 [00:19<00:00, 35434.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03, Train: 0.5994, Val: 0.5846, Test: 0.5242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04: 100%|██████████| 90941/90941 [02:25<00:00, 624.92it/s]\n",
      "Evaluating: 100%|██████████| 677372/677372 [00:26<00:00, 25488.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04, Train: 0.6094, Val: 0.5820, Test: 0.5269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05:  28%|██▊       | 25600/90941 [00:42<01:31, 717.76it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_35351/2285670020.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0mbest_val_acc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfinal_test_acc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m6\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m     \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0macc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m     \u001B[0mtrain_acc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_acc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_acc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'Epoch {epoch:02d}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, '\u001B[0m\u001B[0;34mf'Test: {test_acc:.4f}'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_35351/1748007145.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(epoch)\u001B[0m\n\u001B[1;32m    318\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mn_id\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0madjs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    319\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnll_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mn_id\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 320\u001B[0;31m         \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    321\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    322\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    486\u001B[0m                 \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    487\u001B[0m             )\n\u001B[0;32m--> 488\u001B[0;31m         torch.autograd.backward(\n\u001B[0m\u001B[1;32m    489\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    490\u001B[0m         )\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     \u001B[0;31m# some Python versions print out the first line of a multi-line function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    196\u001B[0m     \u001B[0;31m# calls in the traceback and some print out the last line\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 197\u001B[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001B[0m\u001B[1;32m    198\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    199\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "random_losses = []\n",
    "random_test_accs = []\n",
    "\n",
    "model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay = 0.0)\n",
    "\n",
    "best_val_acc = final_test_acc = 0\n",
    "for epoch in range (1, 6):\n",
    "    loss, acc = train(epoch)\n",
    "    train_acc, val_acc, test_acc = test()\n",
    "    print(f'Epoch {epoch:02d}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, 'f'Test: {test_acc:.4f}')\n",
    "    wandb.log({\"loss\": loss, \"acc\": test_acc})\n",
    "    random_losses.append(loss)\n",
    "    random_test_accs.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/89 [00:00<?, ?it/s]\u001B[A\n",
      "  1%|          | 1/89 [00:00<00:39,  2.25it/s]\u001B[A\n",
      "  2%|▏         | 2/89 [00:00<00:28,  3.10it/s]\u001B[A\n",
      "  3%|▎         | 3/89 [00:00<00:23,  3.61it/s]\u001B[A\n",
      "  4%|▍         | 4/89 [00:01<00:21,  4.02it/s]\u001B[A\n",
      "  6%|▌         | 5/89 [00:01<00:19,  4.25it/s]\u001B[A\n",
      "  7%|▋         | 6/89 [00:01<00:18,  4.39it/s]\u001B[A\n",
      "  8%|▊         | 7/89 [00:01<00:17,  4.77it/s]\u001B[A\n",
      "  9%|▉         | 8/89 [00:01<00:17,  4.75it/s]\u001B[A\n",
      " 10%|█         | 9/89 [00:02<00:16,  4.80it/s]\u001B[A\n",
      " 11%|█         | 10/89 [00:02<00:16,  4.82it/s]\u001B[A\n",
      " 12%|█▏        | 11/89 [00:02<00:17,  4.46it/s]\u001B[A\n",
      " 13%|█▎        | 12/89 [00:02<00:18,  4.24it/s]\u001B[A\n",
      " 15%|█▍        | 13/89 [00:03<00:17,  4.42it/s]\u001B[A\n",
      " 16%|█▌        | 14/89 [00:04<00:42,  1.78it/s]\u001B[A\n",
      " 17%|█▋        | 15/89 [00:04<00:33,  2.20it/s]\u001B[A\n",
      " 18%|█▊        | 16/89 [00:04<00:27,  2.63it/s]\u001B[A\n",
      " 19%|█▉        | 17/89 [00:05<00:24,  2.98it/s]\u001B[A\n",
      " 20%|██        | 18/89 [00:05<00:21,  3.31it/s]\u001B[A\n",
      " 21%|██▏       | 19/89 [00:05<00:19,  3.61it/s]\u001B[A\n",
      " 22%|██▏       | 20/89 [00:05<00:17,  3.98it/s]\u001B[A\n",
      " 24%|██▎       | 21/89 [00:05<00:15,  4.36it/s]\u001B[A\n",
      " 25%|██▍       | 22/89 [00:06<00:14,  4.66it/s]\u001B[A\n",
      " 26%|██▌       | 23/89 [00:06<00:13,  4.82it/s]\u001B[A\n",
      " 27%|██▋       | 24/89 [00:06<00:15,  4.19it/s]\u001B[A\n",
      " 28%|██▊       | 25/89 [00:06<00:15,  4.07it/s]\u001B[A\n",
      " 29%|██▉       | 26/89 [00:06<00:14,  4.36it/s]\u001B[A\n",
      " 30%|███       | 27/89 [00:07<00:14,  4.36it/s]\u001B[A\n",
      " 31%|███▏      | 28/89 [00:07<00:13,  4.40it/s]\u001B[A\n",
      " 33%|███▎      | 29/89 [00:07<00:13,  4.56it/s]\u001B[A\n",
      " 34%|███▎      | 30/89 [00:07<00:12,  4.56it/s]\u001B[A\n",
      " 35%|███▍      | 31/89 [00:08<00:11,  4.90it/s]\u001B[A\n",
      " 36%|███▌      | 32/89 [00:08<00:10,  5.49it/s]\u001B[A\n",
      " 37%|███▋      | 33/89 [00:08<00:10,  5.53it/s]\u001B[A\n",
      " 38%|███▊      | 34/89 [00:08<00:10,  5.45it/s]\u001B[A\n",
      " 39%|███▉      | 35/89 [00:08<00:10,  5.22it/s]\u001B[A\n",
      " 40%|████      | 36/89 [00:08<00:10,  5.29it/s]\u001B[A\n",
      " 42%|████▏     | 37/89 [00:09<00:09,  5.66it/s]\u001B[A\n",
      " 43%|████▎     | 38/89 [00:09<00:09,  5.46it/s]\u001B[A\n",
      " 44%|████▍     | 39/89 [00:09<00:09,  5.14it/s]\u001B[A\n",
      " 45%|████▍     | 40/89 [00:09<00:08,  5.49it/s]\u001B[A\n",
      " 46%|████▌     | 41/89 [00:09<00:08,  5.65it/s]\u001B[A\n",
      " 47%|████▋     | 42/89 [00:10<00:08,  5.28it/s]\u001B[A\n",
      " 48%|████▊     | 43/89 [00:10<00:08,  5.12it/s]\u001B[A\n",
      " 49%|████▉     | 44/89 [00:10<00:11,  3.88it/s]\u001B[A\n",
      " 51%|█████     | 45/89 [00:10<00:11,  3.92it/s]\u001B[A\n",
      " 52%|█████▏    | 46/89 [00:11<00:10,  3.95it/s]\u001B[A\n",
      " 53%|█████▎    | 47/89 [00:11<00:10,  4.14it/s]\u001B[A\n",
      " 54%|█████▍    | 48/89 [00:11<00:08,  4.72it/s]\u001B[A\n",
      " 55%|█████▌    | 49/89 [00:11<00:07,  5.09it/s]\u001B[A\n",
      " 56%|█████▌    | 50/89 [00:11<00:07,  4.96it/s]\u001B[A\n",
      " 57%|█████▋    | 51/89 [00:12<00:07,  5.08it/s]\u001B[A\n",
      " 58%|█████▊    | 52/89 [00:12<00:07,  5.12it/s]\u001B[A\n",
      " 60%|█████▉    | 53/89 [00:12<00:07,  5.00it/s]\u001B[A\n",
      " 61%|██████    | 54/89 [00:12<00:06,  5.03it/s]\u001B[A\n",
      " 62%|██████▏   | 55/89 [00:12<00:06,  5.11it/s]\u001B[A\n",
      " 63%|██████▎   | 56/89 [00:13<00:06,  5.24it/s]\u001B[A\n",
      " 64%|██████▍   | 57/89 [00:13<00:05,  5.61it/s]\u001B[A\n",
      " 65%|██████▌   | 58/89 [00:13<00:05,  5.50it/s]\u001B[A\n",
      " 66%|██████▋   | 59/89 [00:13<00:08,  3.60it/s]\u001B[A\n",
      " 67%|██████▋   | 60/89 [00:14<00:07,  3.99it/s]\u001B[A\n",
      " 69%|██████▊   | 61/89 [00:14<00:06,  4.17it/s]\u001B[A\n",
      " 70%|██████▉   | 62/89 [00:14<00:06,  4.24it/s]\u001B[A\n",
      " 71%|███████   | 63/89 [00:14<00:06,  4.01it/s]\u001B[A\n",
      " 72%|███████▏  | 64/89 [00:14<00:05,  4.29it/s]\u001B[A\n",
      " 73%|███████▎  | 65/89 [00:15<00:05,  4.57it/s]\u001B[A\n",
      " 74%|███████▍  | 66/89 [00:15<00:04,  4.61it/s]\u001B[A\n",
      " 75%|███████▌  | 67/89 [00:15<00:04,  5.12it/s]\u001B[A\n",
      " 76%|███████▋  | 68/89 [00:15<00:04,  4.99it/s]\u001B[A\n",
      " 78%|███████▊  | 69/89 [00:15<00:03,  5.08it/s]\u001B[A\n",
      " 79%|███████▊  | 70/89 [00:16<00:03,  5.63it/s]\u001B[A\n",
      " 80%|███████▉  | 71/89 [00:16<00:03,  5.61it/s]\u001B[A\n",
      " 81%|████████  | 72/89 [00:16<00:03,  5.39it/s]\u001B[A\n",
      " 82%|████████▏ | 73/89 [00:16<00:03,  4.26it/s]\u001B[A\n",
      " 83%|████████▎ | 74/89 [00:17<00:03,  4.19it/s]\u001B[A\n",
      " 84%|████████▍ | 75/89 [00:17<00:03,  4.58it/s]\u001B[A\n",
      " 85%|████████▌ | 76/89 [00:17<00:02,  4.78it/s]\u001B[A\n",
      " 87%|████████▋ | 77/89 [00:17<00:02,  4.77it/s]\u001B[A\n",
      " 88%|████████▊ | 78/89 [00:17<00:02,  4.94it/s]\u001B[A\n",
      " 89%|████████▉ | 79/89 [00:17<00:01,  5.16it/s]\u001B[A\n",
      " 90%|████████▉ | 80/89 [00:18<00:01,  4.90it/s]\u001B[A\n",
      " 91%|█████████ | 81/89 [00:18<00:01,  4.99it/s]\u001B[A\n",
      " 92%|█████████▏| 82/89 [00:18<00:01,  4.76it/s]\u001B[A\n",
      " 93%|█████████▎| 83/89 [00:18<00:01,  4.45it/s]\u001B[A\n",
      " 94%|█████████▍| 84/89 [00:19<00:01,  4.41it/s]\u001B[A\n",
      " 96%|█████████▌| 85/89 [00:19<00:00,  4.49it/s]\u001B[A\n",
      " 97%|█████████▋| 86/89 [00:19<00:00,  4.71it/s]\u001B[A\n",
      " 98%|█████████▊| 87/89 [00:19<00:00,  4.90it/s]\u001B[A\n",
      " 99%|█████████▉| 88/89 [00:19<00:00,  5.17it/s]\u001B[A\n",
      "100%|██████████| 89/89 [00:20<00:00,  4.43it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/89 [00:00<?, ?it/s]\u001B[A\n",
      "  1%|          | 1/89 [00:00<01:15,  1.17it/s]\u001B[A\n",
      "  2%|▏         | 2/89 [00:01<00:43,  1.98it/s]\u001B[A\n",
      "  3%|▎         | 3/89 [00:01<00:30,  2.86it/s]\u001B[A\n",
      "  4%|▍         | 4/89 [00:01<00:24,  3.45it/s]\u001B[A\n",
      "  6%|▌         | 5/89 [00:01<00:22,  3.72it/s]\u001B[A\n",
      "  7%|▋         | 6/89 [00:01<00:20,  4.12it/s]\u001B[A\n",
      "  8%|▊         | 7/89 [00:02<00:18,  4.40it/s]\u001B[A\n",
      "  9%|▉         | 8/89 [00:02<00:18,  4.45it/s]\u001B[A\n",
      " 10%|█         | 9/89 [00:02<00:17,  4.49it/s]\u001B[A\n",
      " 11%|█         | 10/89 [00:02<00:17,  4.46it/s]\u001B[A\n",
      " 12%|█▏        | 11/89 [00:03<00:41,  1.90it/s]\u001B[A\n",
      " 13%|█▎        | 12/89 [00:04<00:32,  2.33it/s]\u001B[A\n",
      " 15%|█▍        | 13/89 [00:04<00:30,  2.53it/s]\u001B[A\n",
      " 16%|█▌        | 14/89 [00:04<00:25,  2.90it/s]\u001B[A\n",
      " 17%|█▋        | 15/89 [00:04<00:22,  3.28it/s]\u001B[A\n",
      " 18%|█▊        | 16/89 [00:05<00:19,  3.82it/s]\u001B[A\n",
      " 19%|█▉        | 17/89 [00:05<00:17,  4.02it/s]\u001B[A\n",
      " 20%|██        | 18/89 [00:05<00:16,  4.37it/s]\u001B[A\n",
      " 21%|██▏       | 19/89 [00:05<00:14,  4.84it/s]\u001B[A\n",
      " 22%|██▏       | 20/89 [00:05<00:13,  4.96it/s]\u001B[A\n",
      " 24%|██▎       | 21/89 [00:06<00:12,  5.26it/s]\u001B[A\n",
      " 25%|██▍       | 22/89 [00:06<00:12,  5.42it/s]\u001B[A\n",
      " 26%|██▌       | 23/89 [00:06<00:12,  5.43it/s]\u001B[A\n",
      " 27%|██▋       | 24/89 [00:06<00:12,  5.08it/s]\u001B[A\n",
      " 28%|██▊       | 25/89 [00:06<00:12,  5.03it/s]\u001B[A\n",
      " 29%|██▉       | 26/89 [00:07<00:12,  4.96it/s]\u001B[A\n",
      " 30%|███       | 27/89 [00:07<00:12,  4.86it/s]\u001B[A\n",
      " 31%|███▏      | 28/89 [00:07<00:12,  4.99it/s]\u001B[A\n",
      " 33%|███▎      | 29/89 [00:07<00:11,  5.37it/s]\u001B[A\n",
      " 34%|███▎      | 30/89 [00:07<00:11,  5.30it/s]\u001B[A\n",
      " 35%|███▍      | 31/89 [00:07<00:10,  5.42it/s]\u001B[A\n",
      " 36%|███▌      | 32/89 [00:08<00:10,  5.31it/s]\u001B[A\n",
      " 37%|███▋      | 33/89 [00:08<00:13,  4.15it/s]\u001B[A\n",
      " 38%|███▊      | 34/89 [00:08<00:13,  4.22it/s]\u001B[A\n",
      " 39%|███▉      | 35/89 [00:08<00:11,  4.63it/s]\u001B[A\n",
      " 40%|████      | 36/89 [00:09<00:11,  4.81it/s]\u001B[A\n",
      " 42%|████▏     | 37/89 [00:09<00:10,  4.89it/s]\u001B[A\n",
      " 43%|████▎     | 38/89 [00:09<00:10,  4.97it/s]\u001B[A\n",
      " 44%|████▍     | 39/89 [00:09<00:09,  5.25it/s]\u001B[A\n",
      " 45%|████▍     | 40/89 [00:09<00:09,  5.22it/s]\u001B[A\n",
      " 46%|████▌     | 41/89 [00:10<00:09,  5.23it/s]\u001B[A\n",
      " 47%|████▋     | 42/89 [00:10<00:08,  5.84it/s]\u001B[A\n",
      " 48%|████▊     | 43/89 [00:10<00:07,  6.14it/s]\u001B[A\n",
      " 49%|████▉     | 44/89 [00:10<00:07,  5.81it/s]\u001B[A\n",
      " 51%|█████     | 45/89 [00:10<00:08,  5.41it/s]\u001B[A\n",
      " 52%|█████▏    | 46/89 [00:10<00:07,  5.47it/s]\u001B[A\n",
      " 53%|█████▎    | 47/89 [00:11<00:07,  5.77it/s]\u001B[A\n",
      " 54%|█████▍    | 48/89 [00:11<00:08,  5.09it/s]\u001B[A\n",
      " 55%|█████▌    | 49/89 [00:11<00:08,  4.64it/s]\u001B[A\n",
      " 56%|█████▌    | 50/89 [00:11<00:07,  4.95it/s]\u001B[A\n",
      " 57%|█████▋    | 51/89 [00:11<00:07,  5.35it/s]\u001B[A\n",
      " 58%|█████▊    | 52/89 [00:12<00:06,  5.38it/s]\u001B[A\n",
      " 60%|█████▉    | 53/89 [00:12<00:06,  5.41it/s]\u001B[A\n",
      " 61%|██████    | 54/89 [00:12<00:06,  5.14it/s]\u001B[A\n",
      " 62%|██████▏   | 55/89 [00:12<00:06,  5.08it/s]\u001B[A\n",
      " 63%|██████▎   | 56/89 [00:12<00:06,  5.24it/s]\u001B[A\n",
      " 64%|██████▍   | 57/89 [00:13<00:06,  5.19it/s]\u001B[A\n",
      " 65%|██████▌   | 58/89 [00:13<00:05,  5.20it/s]\u001B[A\n",
      " 66%|██████▋   | 59/89 [00:13<00:05,  5.14it/s]\u001B[A\n",
      " 67%|██████▋   | 60/89 [00:13<00:05,  5.22it/s]\u001B[A\n",
      " 69%|██████▊   | 61/89 [00:13<00:05,  5.28it/s]\u001B[A\n",
      " 70%|██████▉   | 62/89 [00:13<00:05,  5.32it/s]\u001B[A\n",
      " 71%|███████   | 63/89 [00:14<00:04,  5.53it/s]\u001B[A\n",
      " 72%|███████▏  | 64/89 [00:14<00:04,  5.49it/s]\u001B[A\n",
      " 73%|███████▎  | 65/89 [00:14<00:05,  4.79it/s]\u001B[A\n",
      " 74%|███████▍  | 66/89 [00:14<00:04,  4.67it/s]\u001B[A\n",
      " 75%|███████▌  | 67/89 [00:14<00:04,  4.89it/s]\u001B[A\n",
      " 76%|███████▋  | 68/89 [00:15<00:04,  5.22it/s]\u001B[A\n",
      " 78%|███████▊  | 69/89 [00:15<00:03,  5.10it/s]\u001B[A\n",
      " 79%|███████▊  | 70/89 [00:15<00:03,  4.98it/s]\u001B[A\n",
      " 80%|███████▉  | 71/89 [00:15<00:03,  5.04it/s]\u001B[A\n",
      " 81%|████████  | 72/89 [00:15<00:03,  5.21it/s]\u001B[A\n",
      " 82%|████████▏ | 73/89 [00:16<00:02,  5.36it/s]\u001B[A\n",
      " 83%|████████▎ | 74/89 [00:16<00:02,  5.15it/s]\u001B[A\n",
      " 84%|████████▍ | 75/89 [00:16<00:02,  5.09it/s]\u001B[A\n",
      " 85%|████████▌ | 76/89 [00:16<00:02,  5.06it/s]\u001B[A\n",
      " 87%|████████▋ | 77/89 [00:16<00:02,  5.50it/s]\u001B[A\n",
      " 88%|████████▊ | 78/89 [00:17<00:02,  5.45it/s]\u001B[A\n",
      " 89%|████████▉ | 79/89 [00:17<00:02,  4.84it/s]\u001B[A\n",
      " 90%|████████▉ | 80/89 [00:17<00:01,  4.94it/s]\u001B[A\n",
      " 91%|█████████ | 81/89 [00:17<00:01,  5.10it/s]\u001B[A\n",
      " 92%|█████████▏| 82/89 [00:17<00:01,  5.52it/s]\u001B[A\n",
      " 93%|█████████▎| 83/89 [00:17<00:01,  5.68it/s]\u001B[A\n",
      " 94%|█████████▍| 84/89 [00:18<00:00,  5.60it/s]\u001B[A\n",
      " 96%|█████████▌| 85/89 [00:18<00:00,  4.88it/s]\u001B[A\n",
      " 97%|█████████▋| 86/89 [00:18<00:00,  4.69it/s]\u001B[A\n",
      " 98%|█████████▊| 87/89 [00:18<00:00,  4.94it/s]\u001B[A\n",
      " 99%|█████████▉| 88/89 [00:18<00:00,  5.49it/s]\u001B[A\n",
      "100%|██████████| 89/89 [00:19<00:00,  4.64it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/89 [00:00<?, ?it/s]\u001B[A\n",
      "  1%|          | 1/89 [00:00<00:35,  2.51it/s]\u001B[A\n",
      "  2%|▏         | 2/89 [00:00<00:23,  3.70it/s]\u001B[A\n",
      "  3%|▎         | 3/89 [00:00<00:18,  4.71it/s]\u001B[A\n",
      "  4%|▍         | 4/89 [00:00<00:17,  4.91it/s]\u001B[A\n",
      "  6%|▌         | 5/89 [00:01<00:17,  4.88it/s]\u001B[A\n",
      "  7%|▋         | 6/89 [00:01<00:16,  4.93it/s]\u001B[A\n",
      "  8%|▊         | 7/89 [00:01<00:16,  4.87it/s]\u001B[A\n",
      "  9%|▉         | 8/89 [00:01<00:15,  5.17it/s]\u001B[A\n",
      " 10%|█         | 9/89 [00:01<00:15,  5.28it/s]\u001B[A\n",
      " 11%|█         | 10/89 [00:02<00:15,  5.11it/s]\u001B[A\n",
      " 12%|█▏        | 11/89 [00:02<00:14,  5.36it/s]\u001B[A\n",
      " 13%|█▎        | 12/89 [00:02<00:13,  5.61it/s]\u001B[A\n",
      " 15%|█▍        | 13/89 [00:02<00:13,  5.43it/s]\u001B[A\n",
      " 16%|█▌        | 14/89 [00:02<00:14,  5.30it/s]\u001B[A\n",
      " 17%|█▋        | 15/89 [00:03<00:25,  2.90it/s]\u001B[A\n",
      " 18%|█▊        | 16/89 [00:03<00:24,  2.95it/s]\u001B[A\n",
      " 19%|█▉        | 17/89 [00:04<00:21,  3.41it/s]\u001B[A\n",
      " 20%|██        | 18/89 [00:04<00:18,  3.76it/s]\u001B[A\n",
      " 21%|██▏       | 19/89 [00:04<00:18,  3.81it/s]\u001B[A\n",
      " 22%|██▏       | 20/89 [00:04<00:17,  4.01it/s]\u001B[A\n",
      " 24%|██▎       | 21/89 [00:04<00:15,  4.36it/s]\u001B[A\n",
      " 25%|██▍       | 22/89 [00:05<00:13,  4.86it/s]\u001B[A\n",
      " 26%|██▌       | 23/89 [00:05<00:16,  4.11it/s]\u001B[A\n",
      " 27%|██▋       | 24/89 [00:05<00:15,  4.12it/s]\u001B[A\n",
      " 28%|██▊       | 25/89 [00:05<00:14,  4.38it/s]\u001B[A\n",
      " 29%|██▉       | 26/89 [00:06<00:13,  4.51it/s]\u001B[A\n",
      " 30%|███       | 27/89 [00:06<00:13,  4.62it/s]\u001B[A\n",
      " 31%|███▏      | 28/89 [00:06<00:13,  4.56it/s]\u001B[A\n",
      " 33%|███▎      | 29/89 [00:06<00:12,  4.71it/s]\u001B[A\n",
      " 34%|███▎      | 30/89 [00:06<00:12,  4.82it/s]\u001B[A\n",
      " 35%|███▍      | 31/89 [00:07<00:11,  4.87it/s]\u001B[A\n",
      " 36%|███▌      | 32/89 [00:07<00:12,  4.71it/s]\u001B[A\n",
      " 37%|███▋      | 33/89 [00:07<00:11,  5.07it/s]\u001B[A\n",
      " 38%|███▊      | 34/89 [00:07<00:10,  5.31it/s]\u001B[A\n",
      " 39%|███▉      | 35/89 [00:07<00:10,  5.33it/s]\u001B[A\n",
      " 40%|████      | 36/89 [00:07<00:09,  5.76it/s]\u001B[A\n",
      " 42%|████▏     | 37/89 [00:08<00:10,  5.08it/s]\u001B[A\n",
      " 43%|████▎     | 38/89 [00:08<00:09,  5.46it/s]\u001B[A\n",
      " 44%|████▍     | 39/89 [00:08<00:09,  5.38it/s]\u001B[A\n",
      " 45%|████▍     | 40/89 [00:08<00:08,  5.86it/s]\u001B[A\n",
      " 46%|████▌     | 41/89 [00:08<00:08,  5.54it/s]\u001B[A\n",
      " 47%|████▋     | 42/89 [00:09<00:09,  5.14it/s]\u001B[A\n",
      " 48%|████▊     | 43/89 [00:09<00:10,  4.19it/s]\u001B[A\n",
      " 49%|████▉     | 44/89 [00:09<00:10,  4.29it/s]\u001B[A\n",
      " 51%|█████     | 45/89 [00:09<00:09,  4.47it/s]\u001B[A\n",
      " 52%|█████▏    | 46/89 [00:10<00:09,  4.77it/s]\u001B[A\n",
      " 53%|█████▎    | 47/89 [00:10<00:08,  4.88it/s]\u001B[A\n",
      " 54%|█████▍    | 48/89 [00:10<00:08,  4.95it/s]\u001B[A\n",
      " 55%|█████▌    | 49/89 [00:10<00:07,  5.09it/s]\u001B[A\n",
      " 56%|█████▌    | 50/89 [00:10<00:07,  5.13it/s]\u001B[A\n",
      " 57%|█████▋    | 51/89 [00:10<00:07,  5.32it/s]\u001B[A\n",
      " 58%|█████▊    | 52/89 [00:11<00:08,  4.50it/s]\u001B[A\n",
      " 60%|█████▉    | 53/89 [00:11<00:08,  4.40it/s]\u001B[A\n",
      " 61%|██████    | 54/89 [00:11<00:07,  4.66it/s]\u001B[A\n",
      " 62%|██████▏   | 55/89 [00:11<00:06,  5.09it/s]\u001B[A\n",
      " 63%|██████▎   | 56/89 [00:11<00:06,  5.37it/s]\u001B[A\n",
      " 64%|██████▍   | 57/89 [00:12<00:05,  5.34it/s]\u001B[A\n",
      " 65%|██████▌   | 58/89 [00:12<00:05,  5.39it/s]\u001B[A\n",
      " 66%|██████▋   | 59/89 [00:12<00:05,  5.27it/s]\u001B[A\n",
      " 67%|██████▋   | 60/89 [00:12<00:05,  5.36it/s]\u001B[A\n",
      " 69%|██████▊   | 61/89 [00:12<00:04,  5.62it/s]\u001B[A\n",
      " 70%|██████▉   | 62/89 [00:13<00:04,  5.45it/s]\u001B[A\n",
      " 71%|███████   | 63/89 [00:13<00:04,  5.48it/s]\u001B[A\n",
      " 72%|███████▏  | 64/89 [00:13<00:04,  5.33it/s]\u001B[A\n",
      " 73%|███████▎  | 65/89 [00:13<00:04,  5.33it/s]\u001B[A\n",
      " 74%|███████▍  | 66/89 [00:13<00:04,  5.66it/s]\u001B[A\n",
      " 75%|███████▌  | 67/89 [00:13<00:03,  5.84it/s]\u001B[A\n",
      " 76%|███████▋  | 68/89 [00:14<00:03,  5.52it/s]\u001B[A\n",
      " 78%|███████▊  | 69/89 [00:14<00:03,  5.74it/s]\u001B[A\n",
      " 79%|███████▊  | 70/89 [00:14<00:03,  5.63it/s]\u001B[A\n",
      " 80%|███████▉  | 71/89 [00:14<00:03,  5.88it/s]\u001B[A\n",
      " 81%|████████  | 72/89 [00:14<00:03,  5.62it/s]\u001B[A\n",
      " 82%|████████▏ | 73/89 [00:15<00:03,  5.08it/s]\u001B[A\n",
      " 83%|████████▎ | 74/89 [00:15<00:03,  4.73it/s]\u001B[A\n",
      " 84%|████████▍ | 75/89 [00:15<00:03,  4.53it/s]\u001B[A\n",
      " 85%|████████▌ | 76/89 [00:15<00:02,  4.47it/s]\u001B[A\n",
      " 87%|████████▋ | 77/89 [00:16<00:02,  4.03it/s]\u001B[A\n",
      " 88%|████████▊ | 78/89 [00:16<00:02,  4.01it/s]\u001B[A\n",
      " 89%|████████▉ | 79/89 [00:16<00:02,  4.22it/s]\u001B[A\n",
      " 90%|████████▉ | 80/89 [00:16<00:01,  4.55it/s]\u001B[A\n",
      " 91%|█████████ | 81/89 [00:16<00:01,  5.11it/s]\u001B[A\n",
      " 92%|█████████▏| 82/89 [00:17<00:01,  5.05it/s]\u001B[A\n",
      " 93%|█████████▎| 83/89 [00:17<00:01,  4.22it/s]\u001B[A\n",
      " 94%|█████████▍| 84/89 [00:17<00:01,  4.34it/s]\u001B[A\n",
      " 96%|█████████▌| 85/89 [00:17<00:00,  4.52it/s]\u001B[A\n",
      " 97%|█████████▋| 86/89 [00:18<00:00,  4.78it/s]\u001B[A\n",
      " 98%|█████████▊| 87/89 [00:18<00:00,  4.90it/s]\u001B[A\n",
      " 99%|█████████▉| 88/89 [00:18<00:00,  4.87it/s]\u001B[A\n",
      "100%|██████████| 89/89 [00:18<00:00,  4.76it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/89 [00:00<?, ?it/s]\u001B[A\n",
      "  1%|          | 1/89 [00:00<00:37,  2.33it/s]\u001B[A\n",
      "  2%|▏         | 2/89 [00:00<00:26,  3.32it/s]\u001B[A\n",
      "  3%|▎         | 3/89 [00:00<00:21,  3.95it/s]\u001B[A\n",
      "  4%|▍         | 4/89 [00:01<00:19,  4.40it/s]\u001B[A\n",
      "  6%|▌         | 5/89 [00:01<00:17,  4.87it/s]\u001B[A\n",
      "  7%|▋         | 6/89 [00:01<00:16,  4.91it/s]\u001B[A\n",
      "  8%|▊         | 7/89 [00:01<00:16,  5.11it/s]\u001B[A\n",
      "  9%|▉         | 8/89 [00:01<00:14,  5.43it/s]\u001B[A\n",
      " 10%|█         | 9/89 [00:01<00:14,  5.42it/s]\u001B[A\n",
      " 11%|█         | 10/89 [00:02<00:13,  5.86it/s]\u001B[A\n",
      " 12%|█▏        | 11/89 [00:02<00:13,  5.69it/s]\u001B[A\n",
      " 13%|█▎        | 12/89 [00:02<00:14,  5.21it/s]\u001B[A\n",
      " 15%|█▍        | 13/89 [00:02<00:15,  4.87it/s]\u001B[A\n",
      " 16%|█▌        | 14/89 [00:02<00:15,  4.79it/s]\u001B[A\n",
      " 17%|█▋        | 15/89 [00:03<00:14,  5.07it/s]\u001B[A\n",
      " 18%|█▊        | 16/89 [00:03<00:14,  5.14it/s]\u001B[A\n",
      " 19%|█▉        | 17/89 [00:03<00:18,  3.89it/s]\u001B[A\n",
      " 20%|██        | 18/89 [00:04<00:21,  3.37it/s]\u001B[A\n",
      " 21%|██▏       | 19/89 [00:04<00:19,  3.53it/s]\u001B[A\n",
      " 22%|██▏       | 20/89 [00:04<00:21,  3.25it/s]\u001B[A\n",
      " 24%|██▎       | 21/89 [00:04<00:18,  3.64it/s]\u001B[A\n",
      " 25%|██▍       | 22/89 [00:05<00:16,  4.15it/s]\u001B[A\n",
      " 26%|██▌       | 23/89 [00:05<00:15,  4.35it/s]\u001B[A\n",
      " 27%|██▋       | 24/89 [00:05<00:14,  4.55it/s]\u001B[A\n",
      " 28%|██▊       | 25/89 [00:05<00:12,  5.17it/s]\u001B[A\n",
      " 29%|██▉       | 26/89 [00:05<00:11,  5.49it/s]\u001B[A\n",
      " 30%|███       | 27/89 [00:05<00:11,  5.41it/s]\u001B[A\n",
      " 31%|███▏      | 28/89 [00:06<00:11,  5.52it/s]\u001B[A\n",
      " 33%|███▎      | 29/89 [00:06<00:11,  5.27it/s]\u001B[A\n",
      " 34%|███▎      | 30/89 [00:06<00:11,  5.07it/s]\u001B[A\n",
      " 35%|███▍      | 31/89 [00:06<00:11,  5.06it/s]\u001B[A\n",
      " 36%|███▌      | 32/89 [00:06<00:10,  5.37it/s]\u001B[A\n",
      " 37%|███▋      | 33/89 [00:07<00:10,  5.41it/s]\u001B[A\n",
      " 38%|███▊      | 34/89 [00:07<00:10,  5.29it/s]\u001B[A\n",
      " 39%|███▉      | 35/89 [00:07<00:10,  5.26it/s]\u001B[A\n",
      " 40%|████      | 36/89 [00:07<00:10,  5.14it/s]\u001B[A\n",
      " 42%|████▏     | 37/89 [00:07<00:09,  5.23it/s]\u001B[A\n",
      " 43%|████▎     | 38/89 [00:08<00:09,  5.38it/s]\u001B[A\n",
      " 44%|████▍     | 39/89 [00:08<00:09,  5.35it/s]\u001B[A\n",
      " 45%|████▍     | 40/89 [00:08<00:10,  4.77it/s]\u001B[A\n",
      " 46%|████▌     | 41/89 [00:08<00:11,  4.34it/s]\u001B[A\n",
      " 47%|████▋     | 42/89 [00:08<00:10,  4.56it/s]\u001B[A\n",
      " 48%|████▊     | 43/89 [00:09<00:09,  5.00it/s]\u001B[A\n",
      " 49%|████▉     | 44/89 [00:09<00:08,  5.06it/s]\u001B[A\n",
      " 51%|█████     | 45/89 [00:09<00:08,  5.06it/s]\u001B[A\n",
      " 52%|█████▏    | 46/89 [00:09<00:08,  5.06it/s]\u001B[A\n",
      " 53%|█████▎    | 47/89 [00:09<00:08,  5.20it/s]\u001B[A\n",
      " 54%|█████▍    | 48/89 [00:10<00:07,  5.66it/s]\u001B[A\n",
      " 55%|█████▌    | 49/89 [00:10<00:06,  5.87it/s]\u001B[A\n",
      " 56%|█████▌    | 50/89 [00:10<00:06,  5.62it/s]\u001B[A\n",
      " 57%|█████▋    | 51/89 [00:10<00:06,  5.44it/s]\u001B[A\n",
      " 58%|█████▊    | 52/89 [00:10<00:06,  5.42it/s]\u001B[A\n",
      " 60%|█████▉    | 53/89 [00:10<00:06,  5.62it/s]\u001B[A\n",
      " 61%|██████    | 54/89 [00:11<00:05,  5.92it/s]\u001B[A\n",
      " 62%|██████▏   | 55/89 [00:11<00:05,  5.82it/s]\u001B[A\n",
      " 63%|██████▎   | 56/89 [00:11<00:05,  5.64it/s]\u001B[A\n",
      " 64%|██████▍   | 57/89 [00:11<00:05,  5.39it/s]\u001B[A\n",
      " 65%|██████▌   | 58/89 [00:11<00:06,  4.56it/s]\u001B[A\n",
      " 66%|██████▋   | 59/89 [00:12<00:06,  4.69it/s]\u001B[A\n",
      " 67%|██████▋   | 60/89 [00:12<00:05,  5.28it/s]\u001B[A\n",
      " 69%|██████▊   | 61/89 [00:12<00:05,  5.40it/s]\u001B[A\n",
      " 70%|██████▉   | 62/89 [00:12<00:04,  5.74it/s]\u001B[A\n",
      " 71%|███████   | 63/89 [00:12<00:04,  5.43it/s]\u001B[A\n",
      " 72%|███████▏  | 64/89 [00:13<00:04,  5.15it/s]\u001B[A\n",
      " 73%|███████▎  | 65/89 [00:13<00:04,  5.31it/s]\u001B[A\n",
      " 74%|███████▍  | 66/89 [00:13<00:04,  5.24it/s]\u001B[A\n",
      " 75%|███████▌  | 67/89 [00:13<00:03,  5.51it/s]\u001B[A\n",
      " 76%|███████▋  | 68/89 [00:13<00:03,  5.53it/s]\u001B[A\n",
      " 78%|███████▊  | 69/89 [00:13<00:03,  5.55it/s]\u001B[A\n",
      " 79%|███████▊  | 70/89 [00:14<00:03,  5.57it/s]\u001B[A\n",
      " 80%|███████▉  | 71/89 [00:14<00:03,  5.15it/s]\u001B[A\n",
      " 81%|████████  | 72/89 [00:14<00:03,  4.57it/s]\u001B[A\n",
      " 82%|████████▏ | 73/89 [00:14<00:03,  4.41it/s]\u001B[A\n",
      " 83%|████████▎ | 74/89 [00:15<00:03,  4.62it/s]\u001B[A\n",
      " 84%|████████▍ | 75/89 [00:15<00:02,  5.07it/s]\u001B[A\n",
      " 85%|████████▌ | 76/89 [00:15<00:02,  4.99it/s]\u001B[A\n",
      " 87%|████████▋ | 77/89 [00:15<00:02,  5.01it/s]\u001B[A\n",
      " 88%|████████▊ | 78/89 [00:15<00:02,  5.23it/s]\u001B[A\n",
      " 89%|████████▉ | 79/89 [00:15<00:01,  5.59it/s]\u001B[A\n",
      " 90%|████████▉ | 80/89 [00:16<00:01,  5.52it/s]\u001B[A\n",
      " 91%|█████████ | 81/89 [00:16<00:01,  5.36it/s]\u001B[A\n",
      " 92%|█████████▏| 82/89 [00:16<00:01,  5.48it/s]\u001B[A\n",
      " 93%|█████████▎| 83/89 [00:16<00:01,  5.42it/s]\u001B[A\n",
      " 94%|█████████▍| 84/89 [00:16<00:00,  5.43it/s]\u001B[A\n",
      " 96%|█████████▌| 85/89 [00:17<00:00,  5.37it/s]\u001B[A\n",
      " 97%|█████████▋| 86/89 [00:17<00:00,  5.36it/s]\u001B[A\n",
      " 98%|█████████▊| 87/89 [00:17<00:00,  4.80it/s]\u001B[A\n",
      " 99%|█████████▉| 88/89 [00:17<00:00,  4.60it/s]\u001B[A\n",
      "100%|██████████| 89/89 [00:17<00:00,  4.96it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/89 [00:00<?, ?it/s]\u001B[A\n",
      "  1%|          | 1/89 [00:00<00:36,  2.44it/s]\u001B[A\n",
      "  2%|▏         | 2/89 [00:00<00:25,  3.46it/s]\u001B[A\n",
      "  3%|▎         | 3/89 [00:00<00:20,  4.16it/s]\u001B[A\n",
      "  4%|▍         | 4/89 [00:00<00:18,  4.49it/s]\u001B[A\n",
      "  6%|▌         | 5/89 [00:01<00:16,  5.22it/s]\u001B[A\n",
      "  7%|▋         | 6/89 [00:01<00:14,  5.82it/s]\u001B[A\n",
      "  8%|▊         | 7/89 [00:01<00:14,  5.57it/s]\u001B[A\n",
      "  9%|▉         | 8/89 [00:01<00:15,  5.39it/s]\u001B[A\n",
      " 10%|█         | 9/89 [00:01<00:14,  5.45it/s]\u001B[A\n",
      " 11%|█         | 10/89 [00:02<00:14,  5.30it/s]\u001B[A\n",
      " 12%|█▏        | 11/89 [00:02<00:15,  4.96it/s]\u001B[A\n",
      " 13%|█▎        | 12/89 [00:02<00:15,  4.85it/s]\u001B[A\n",
      " 15%|█▍        | 13/89 [00:02<00:16,  4.60it/s]\u001B[A\n",
      " 16%|█▌        | 14/89 [00:02<00:16,  4.52it/s]\u001B[A\n",
      " 17%|█▋        | 15/89 [00:03<00:15,  4.65it/s]\u001B[A\n",
      " 18%|█▊        | 16/89 [00:03<00:19,  3.84it/s]\u001B[A\n",
      " 19%|█▉        | 17/89 [00:03<00:17,  4.08it/s]\u001B[A\n",
      " 20%|██        | 18/89 [00:03<00:16,  4.39it/s]\u001B[A\n",
      " 21%|██▏       | 19/89 [00:04<00:15,  4.63it/s]\u001B[A\n",
      " 22%|██▏       | 20/89 [00:04<00:13,  5.03it/s]\u001B[A\n",
      " 24%|██▎       | 21/89 [00:04<00:13,  5.19it/s]\u001B[A\n",
      " 25%|██▍       | 22/89 [00:04<00:13,  5.02it/s]\u001B[A\n",
      " 26%|██▌       | 23/89 [00:04<00:12,  5.26it/s]\u001B[A\n",
      " 27%|██▋       | 24/89 [00:04<00:11,  5.51it/s]\u001B[A\n",
      " 28%|██▊       | 25/89 [00:05<00:16,  3.88it/s]\u001B[A\n",
      " 29%|██▉       | 26/89 [00:05<00:19,  3.20it/s]\u001B[A\n",
      " 30%|███       | 27/89 [00:06<00:17,  3.63it/s]\u001B[A\n",
      " 31%|███▏      | 28/89 [00:06<00:15,  4.02it/s]\u001B[A\n",
      " 33%|███▎      | 29/89 [00:06<00:13,  4.34it/s]\u001B[A\n",
      " 34%|███▎      | 30/89 [00:06<00:13,  4.32it/s]\u001B[A\n",
      " 35%|███▍      | 31/89 [00:06<00:14,  4.04it/s]\u001B[A\n",
      " 36%|███▌      | 32/89 [00:07<00:13,  4.32it/s]\u001B[A\n",
      " 37%|███▋      | 33/89 [00:07<00:12,  4.65it/s]\u001B[A\n",
      " 38%|███▊      | 34/89 [00:07<00:11,  4.91it/s]\u001B[A\n",
      " 39%|███▉      | 35/89 [00:07<00:10,  5.20it/s]\u001B[A\n",
      " 40%|████      | 36/89 [00:07<00:10,  5.24it/s]\u001B[A\n",
      " 42%|████▏     | 37/89 [00:08<00:09,  5.42it/s]\u001B[A\n",
      " 43%|████▎     | 38/89 [00:08<00:08,  5.70it/s]\u001B[A\n",
      " 44%|████▍     | 39/89 [00:08<00:08,  5.56it/s]\u001B[A\n",
      " 45%|████▍     | 40/89 [00:08<00:09,  5.22it/s]\u001B[A\n",
      " 46%|████▌     | 41/89 [00:08<00:09,  5.12it/s]\u001B[A\n",
      " 47%|████▋     | 42/89 [00:08<00:08,  5.34it/s]\u001B[A\n",
      " 48%|████▊     | 43/89 [00:09<00:08,  5.52it/s]\u001B[A\n",
      " 49%|████▉     | 44/89 [00:09<00:10,  4.14it/s]\u001B[A\n",
      " 51%|█████     | 45/89 [00:09<00:10,  4.39it/s]\u001B[A\n",
      " 52%|█████▏    | 46/89 [00:09<00:09,  4.76it/s]\u001B[A\n",
      " 53%|█████▎    | 47/89 [00:10<00:08,  4.99it/s]\u001B[A\n",
      " 54%|█████▍    | 48/89 [00:10<00:07,  5.30it/s]\u001B[A\n",
      " 55%|█████▌    | 49/89 [00:10<00:07,  5.58it/s]\u001B[A\n",
      " 56%|█████▌    | 50/89 [00:10<00:08,  4.57it/s]\u001B[A\n",
      " 57%|█████▋    | 51/89 [00:10<00:08,  4.69it/s]\u001B[A\n",
      " 58%|█████▊    | 52/89 [00:11<00:07,  4.84it/s]\u001B[A\n",
      " 60%|█████▉    | 53/89 [00:11<00:06,  5.30it/s]\u001B[A\n",
      " 61%|██████    | 54/89 [00:11<00:06,  5.28it/s]\u001B[A\n",
      " 62%|██████▏   | 55/89 [00:11<00:06,  5.44it/s]\u001B[A\n",
      " 63%|██████▎   | 56/89 [00:11<00:05,  5.80it/s]\u001B[A\n",
      " 64%|██████▍   | 57/89 [00:11<00:05,  5.66it/s]\u001B[A\n",
      " 65%|██████▌   | 58/89 [00:12<00:05,  5.69it/s]\u001B[A\n",
      " 66%|██████▋   | 59/89 [00:12<00:05,  5.63it/s]\u001B[A\n",
      " 67%|██████▋   | 60/89 [00:12<00:05,  5.59it/s]\u001B[A\n",
      " 69%|██████▊   | 61/89 [00:12<00:05,  5.16it/s]\u001B[A\n",
      " 70%|██████▉   | 62/89 [00:12<00:05,  5.27it/s]\u001B[A\n",
      " 71%|███████   | 63/89 [00:13<00:04,  5.34it/s]\u001B[A\n",
      " 72%|███████▏  | 64/89 [00:13<00:04,  5.12it/s]\u001B[A\n",
      " 73%|███████▎  | 65/89 [00:13<00:04,  4.91it/s]\u001B[A\n",
      " 74%|███████▍  | 66/89 [00:13<00:04,  4.90it/s]\u001B[A\n",
      " 75%|███████▌  | 67/89 [00:14<00:05,  4.04it/s]\u001B[A\n",
      " 76%|███████▋  | 68/89 [00:14<00:04,  4.32it/s]\u001B[A\n",
      " 78%|███████▊  | 69/89 [00:14<00:04,  4.53it/s]\u001B[A\n",
      " 79%|███████▊  | 70/89 [00:14<00:04,  4.66it/s]\u001B[A\n",
      " 80%|███████▉  | 71/89 [00:14<00:03,  4.73it/s]\u001B[A\n",
      " 81%|████████  | 72/89 [00:15<00:03,  4.85it/s]\u001B[A\n",
      " 82%|████████▏ | 73/89 [00:15<00:02,  5.33it/s]\u001B[A\n",
      " 83%|████████▎ | 74/89 [00:15<00:02,  5.69it/s]\u001B[A\n",
      " 84%|████████▍ | 75/89 [00:15<00:02,  5.41it/s]\u001B[A\n",
      " 85%|████████▌ | 76/89 [00:15<00:02,  5.27it/s]\u001B[A\n",
      " 87%|████████▋ | 77/89 [00:15<00:02,  5.41it/s]\u001B[A\n",
      " 88%|████████▊ | 78/89 [00:16<00:01,  5.57it/s]\u001B[A\n",
      " 89%|████████▉ | 79/89 [00:16<00:01,  5.85it/s]\u001B[A\n",
      " 90%|████████▉ | 80/89 [00:16<00:01,  5.67it/s]\u001B[A\n",
      " 91%|█████████ | 81/89 [00:16<00:01,  5.51it/s]\u001B[A\n",
      " 92%|█████████▏| 82/89 [00:16<00:01,  5.20it/s]\u001B[A\n",
      " 93%|█████████▎| 83/89 [00:17<00:01,  5.11it/s]\u001B[A\n",
      " 94%|█████████▍| 84/89 [00:17<00:00,  5.24it/s]\u001B[A\n",
      " 96%|█████████▌| 85/89 [00:17<00:00,  4.78it/s]\u001B[A\n",
      " 97%|█████████▋| 86/89 [00:17<00:00,  4.67it/s]\u001B[A\n",
      " 98%|█████████▊| 87/89 [00:17<00:00,  4.78it/s]\u001B[A\n",
      " 99%|█████████▉| 88/89 [00:18<00:00,  4.98it/s]\u001B[A\n",
      "100%|██████████| 89/89 [00:18<00:00,  4.87it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/166 [00:00<?, ?it/s]\u001B[A\n",
      "  1%|          | 1/166 [00:00<00:33,  4.87it/s]\u001B[A\n",
      "  2%|▏         | 4/166 [00:00<00:11, 14.62it/s]\u001B[A\n",
      "  5%|▍         | 8/166 [00:00<00:07, 21.82it/s]\u001B[A\n",
      "  7%|▋         | 12/166 [00:00<00:06, 25.63it/s]\u001B[A\n",
      " 10%|▉         | 16/166 [00:00<00:05, 27.48it/s]\u001B[A\n",
      " 11%|█▏        | 19/166 [00:00<00:05, 26.73it/s]\u001B[A\n",
      " 14%|█▍        | 23/166 [00:00<00:05, 27.99it/s]\u001B[A\n",
      " 16%|█▌        | 26/166 [00:01<00:05, 28.00it/s]\u001B[A\n",
      " 17%|█▋        | 29/166 [00:01<00:05, 25.29it/s]\u001B[A\n",
      " 19%|█▉        | 32/166 [00:01<00:05, 24.41it/s]\u001B[A\n",
      " 21%|██        | 35/166 [00:01<00:05, 24.98it/s]\u001B[A\n",
      " 23%|██▎       | 38/166 [00:01<00:05, 23.64it/s]\u001B[A\n",
      " 25%|██▍       | 41/166 [00:01<00:05, 24.56it/s]\u001B[A\n",
      " 27%|██▋       | 44/166 [00:01<00:04, 24.98it/s]\u001B[A\n",
      " 28%|██▊       | 47/166 [00:01<00:04, 25.38it/s]\u001B[A\n",
      " 31%|███       | 51/166 [00:02<00:04, 27.99it/s]\u001B[A\n",
      " 33%|███▎      | 54/166 [00:02<00:04, 27.76it/s]\u001B[A\n",
      " 34%|███▍      | 57/166 [00:02<00:04, 26.95it/s]\u001B[A\n",
      " 36%|███▌      | 60/166 [00:02<00:04, 25.21it/s]\u001B[A\n",
      " 38%|███▊      | 63/166 [00:02<00:05, 19.05it/s]\u001B[A\n",
      " 40%|███▉      | 66/166 [00:02<00:04, 21.14it/s]\u001B[A\n",
      " 42%|████▏     | 69/166 [00:02<00:04, 22.98it/s]\u001B[A\n",
      " 43%|████▎     | 72/166 [00:02<00:03, 24.14it/s]\u001B[A\n",
      " 45%|████▌     | 75/166 [00:03<00:03, 24.08it/s]\u001B[A\n",
      " 47%|████▋     | 78/166 [00:03<00:03, 25.36it/s]\u001B[A\n",
      " 49%|████▉     | 81/166 [00:03<00:03, 26.16it/s]\u001B[A\n",
      " 51%|█████     | 85/166 [00:03<00:02, 28.12it/s]\u001B[A\n",
      " 53%|█████▎    | 88/166 [00:03<00:02, 28.52it/s]\u001B[A\n",
      " 55%|█████▍    | 91/166 [00:03<00:02, 27.69it/s]\u001B[A\n",
      " 57%|█████▋    | 95/166 [00:03<00:02, 29.83it/s]\u001B[A\n",
      " 60%|█████▉    | 99/166 [00:03<00:02, 31.08it/s]\u001B[A\n",
      " 62%|██████▏   | 103/166 [00:04<00:02, 28.73it/s]\u001B[A\n",
      " 64%|██████▍   | 106/166 [00:04<00:02, 25.20it/s]\u001B[A\n",
      " 66%|██████▌   | 109/166 [00:04<00:02, 24.93it/s]\u001B[A\n",
      " 67%|██████▋   | 112/166 [00:04<00:02, 24.90it/s]\u001B[A\n",
      " 69%|██████▉   | 115/166 [00:04<00:01, 26.00it/s]\u001B[A\n",
      " 71%|███████   | 118/166 [00:04<00:01, 26.63it/s]\u001B[A\n",
      " 73%|███████▎  | 121/166 [00:04<00:01, 26.73it/s]\u001B[A\n",
      " 75%|███████▍  | 124/166 [00:04<00:01, 27.01it/s]\u001B[A\n",
      " 77%|███████▋  | 127/166 [00:04<00:01, 27.37it/s]\u001B[A\n",
      " 78%|███████▊  | 130/166 [00:05<00:01, 26.53it/s]\u001B[A\n",
      " 80%|████████  | 133/166 [00:05<00:01, 25.98it/s]\u001B[A\n",
      " 83%|████████▎ | 137/166 [00:05<00:01, 28.38it/s]\u001B[A\n",
      " 85%|████████▍ | 141/166 [00:05<00:00, 30.33it/s]\u001B[A\n",
      " 87%|████████▋ | 145/166 [00:05<00:00, 29.93it/s]\u001B[A\n",
      " 90%|████████▉ | 149/166 [00:05<00:00, 29.33it/s]\u001B[A\n",
      " 92%|█████████▏| 152/166 [00:05<00:00, 28.14it/s]\u001B[A\n",
      " 94%|█████████▍| 156/166 [00:05<00:00, 29.60it/s]\u001B[A\n",
      " 96%|█████████▌| 159/166 [00:06<00:00, 29.53it/s]\u001B[A\n",
      " 98%|█████████▊| 162/166 [00:06<00:00, 28.92it/s]\u001B[A\n",
      "100%|██████████| 166/166 [00:06<00:00, 25.50it/s]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc_init, val_acc_init, test_acc_init: 0.0042994908787015755 0.004026980771166817 0.004917391930539267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_mlpinit.reset_parameters()\n",
    "\n",
    "for epoch in range(1, 6):\n",
    "    loss, acc = train_mlpinit()\n",
    "    \n",
    "torch.save(model_mlpinit.state_dict(), f'./model_mlpinit.pt' )\n",
    "train_acc_init, val_acc_init, test_acc_init = test_mlpinit()\n",
    "print(\"train_acc_init, val_acc_init, test_acc_init:\", train_acc_init, val_acc_init, test_acc_init )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/90941 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:   0%|          | 0/90941 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:   1%|          | 1024/90941 [00:01<02:44, 547.82it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:   2%|▏         | 2048/90941 [00:02<02:02, 727.33it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:   3%|▎         | 3072/90941 [00:04<02:18, 632.82it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:   5%|▍         | 4096/90941 [00:06<02:03, 706.03it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:   6%|▌         | 5120/90941 [00:07<02:04, 688.69it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:   7%|▋         | 6144/90941 [00:09<02:01, 695.63it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:   8%|▊         | 7168/90941 [00:10<02:01, 688.16it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:   9%|▉         | 8192/90941 [00:13<02:35, 531.71it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  10%|█         | 9216/90941 [00:15<02:50, 480.00it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  11%|█▏        | 10240/90941 [00:18<03:02, 441.51it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  12%|█▏        | 11264/90941 [00:20<02:55, 453.03it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  14%|█▎        | 12288/90941 [00:23<03:11, 411.76it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  15%|█▍        | 13312/90941 [00:25<02:57, 436.81it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  16%|█▌        | 14336/90941 [00:28<02:57, 432.07it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  17%|█▋        | 15360/90941 [00:30<02:52, 438.46it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  18%|█▊        | 16384/90941 [00:32<02:35, 479.53it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  19%|█▉        | 17408/90941 [00:33<02:19, 527.88it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  20%|██        | 18432/90941 [00:35<02:14, 540.39it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  21%|██▏       | 19456/90941 [00:37<02:08, 554.29it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  23%|██▎       | 20480/90941 [00:39<02:12, 529.91it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  24%|██▎       | 21504/90941 [00:41<02:14, 516.86it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  25%|██▍       | 22528/90941 [00:43<02:06, 539.64it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  26%|██▌       | 23552/90941 [00:45<02:17, 490.57it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  27%|██▋       | 24576/90941 [00:48<02:24, 460.62it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  28%|██▊       | 25600/90941 [00:50<02:19, 467.95it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  29%|██▉       | 26624/90941 [00:52<02:09, 498.20it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  30%|███       | 27648/90941 [00:53<01:58, 535.59it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  32%|███▏      | 28672/90941 [00:55<01:47, 578.46it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  33%|███▎      | 29696/90941 [00:56<01:35, 642.15it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  34%|███▍      | 30720/90941 [00:57<01:34, 638.30it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  35%|███▍      | 31744/90941 [00:59<01:32, 642.38it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  36%|███▌      | 32768/90941 [01:00<01:28, 657.37it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  37%|███▋      | 33792/90941 [01:02<01:24, 673.74it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  38%|███▊      | 34816/90941 [01:04<01:27, 638.11it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  39%|███▉      | 35840/90941 [01:05<01:26, 638.76it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  41%|████      | 36864/90941 [01:07<01:25, 631.04it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  42%|████▏     | 37888/90941 [01:09<01:29, 594.11it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  43%|████▎     | 38912/90941 [01:10<01:24, 616.12it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  44%|████▍     | 39936/90941 [01:12<01:21, 624.62it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  45%|████▌     | 40960/90941 [01:14<01:20, 621.93it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  46%|████▌     | 41984/90941 [01:16<01:27, 561.18it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  47%|████▋     | 43008/90941 [01:17<01:17, 614.63it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  48%|████▊     | 44032/90941 [01:19<01:17, 603.96it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  50%|████▉     | 45056/90941 [01:21<01:16, 598.30it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  51%|█████     | 46080/90941 [01:23<01:16, 582.70it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  52%|█████▏    | 47104/90941 [01:25<01:22, 531.31it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  53%|█████▎    | 48128/90941 [01:26<01:14, 574.23it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  54%|█████▍    | 49152/90941 [01:28<01:10, 591.46it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  55%|█████▌    | 50176/90941 [01:29<01:03, 642.46it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  56%|█████▋    | 51200/90941 [01:31<01:00, 657.86it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  57%|█████▋    | 52224/90941 [01:32<00:57, 671.47it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  59%|█████▊    | 53248/90941 [01:34<01:01, 608.31it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  60%|█████▉    | 54272/90941 [01:37<01:10, 521.20it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  61%|██████    | 55296/90941 [01:39<01:05, 542.68it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  62%|██████▏   | 56320/90941 [01:40<01:02, 557.98it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  63%|██████▎   | 57344/90941 [01:42<01:03, 532.05it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  64%|██████▍   | 58368/90941 [01:44<00:56, 572.23it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  65%|██████▌   | 59392/90941 [01:45<00:52, 602.62it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  66%|██████▋   | 60416/90941 [01:47<00:50, 603.40it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  68%|██████▊   | 61440/90941 [01:49<00:50, 585.41it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  69%|██████▊   | 62464/90941 [01:50<00:47, 605.48it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  70%|██████▉   | 63488/90941 [01:52<00:42, 646.10it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  71%|███████   | 64512/90941 [01:54<00:47, 552.06it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  72%|███████▏  | 65536/90941 [01:56<00:46, 545.54it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  73%|███████▎  | 66560/90941 [01:58<00:42, 576.87it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  74%|███████▍  | 67584/90941 [01:59<00:39, 590.43it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  75%|███████▌  | 68608/90941 [02:01<00:36, 605.47it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  77%|███████▋  | 69632/90941 [02:02<00:32, 649.62it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  78%|███████▊  | 70656/90941 [02:04<00:30, 660.61it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  79%|███████▉  | 71680/90941 [02:05<00:28, 668.02it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  80%|███████▉  | 72704/90941 [02:07<00:30, 604.01it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  81%|████████  | 73728/90941 [02:09<00:29, 586.10it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  82%|████████▏ | 74752/90941 [02:11<00:27, 589.55it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  83%|████████▎ | 75776/90941 [02:13<00:25, 585.89it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  84%|████████▍ | 76800/90941 [02:14<00:22, 638.99it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  86%|████████▌ | 77824/90941 [02:16<00:20, 628.55it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  87%|████████▋ | 78848/90941 [02:18<00:22, 536.75it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  88%|████████▊ | 79872/90941 [02:20<00:19, 562.65it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  89%|████████▉ | 80896/90941 [02:21<00:17, 588.70it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  90%|█████████ | 81920/90941 [02:23<00:14, 607.24it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  91%|█████████ | 82944/90941 [02:24<00:12, 643.57it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  92%|█████████▏| 83968/90941 [02:26<00:10, 664.86it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  93%|█████████▎| 84992/90941 [02:27<00:08, 706.65it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  95%|█████████▍| 86016/90941 [02:28<00:07, 701.67it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  96%|█████████▌| 87040/90941 [02:30<00:05, 696.35it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  97%|█████████▋| 88064/90941 [02:31<00:04, 693.93it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  98%|█████████▊| 89088/90941 [02:34<00:03, 565.18it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01:  99%|█████████▉| 90112/90941 [02:36<00:01, 599.61it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 01: 100%|██████████| 90941/90941 [02:37<00:00, 578.95it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/677372 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   0%|          | 0/677372 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   0%|          | 1024/677372 [00:00<01:52, 6002.53it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   1%|          | 5120/677372 [00:00<00:30, 21825.67it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   2%|▏         | 10240/677372 [00:00<00:20, 32087.95it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   2%|▏         | 14336/677372 [00:00<00:19, 34624.91it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   3%|▎         | 18432/677372 [00:00<00:21, 30828.88it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   3%|▎         | 22528/677372 [00:00<00:25, 25709.31it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   4%|▍         | 25600/677372 [00:01<00:32, 20287.04it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   4%|▍         | 29696/677372 [00:01<00:28, 22841.17it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   5%|▌         | 34816/677372 [00:01<00:23, 27571.84it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   6%|▌         | 39936/677372 [00:01<00:19, 32612.75it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   7%|▋         | 45056/677372 [00:01<00:17, 35709.66it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   7%|▋         | 50176/677372 [00:01<00:16, 37910.33it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   8%|▊         | 54272/677372 [00:01<00:16, 38596.64it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   9%|▉         | 59392/677372 [00:01<00:15, 40759.05it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  10%|▉         | 64512/677372 [00:02<00:14, 41031.36it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  10%|█         | 69632/677372 [00:02<00:14, 41696.86it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  11%|█         | 74752/677372 [00:02<00:14, 42563.28it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  12%|█▏        | 79872/677372 [00:02<00:13, 43900.00it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  13%|█▎        | 84992/677372 [00:02<00:13, 42589.61it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  13%|█▎        | 90112/677372 [00:02<00:14, 41213.32it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  14%|█▍        | 95232/677372 [00:02<00:14, 40570.51it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  15%|█▍        | 100352/677372 [00:02<00:13, 42914.74it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  16%|█▌        | 105472/677372 [00:02<00:12, 44697.75it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  16%|█▋        | 110592/677372 [00:03<00:13, 43313.68it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  17%|█▋        | 115712/677372 [00:03<00:12, 43552.38it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  18%|█▊        | 120832/677372 [00:03<00:12, 43714.51it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  19%|█▊        | 125952/677372 [00:03<00:14, 38524.48it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  19%|█▉        | 130048/677372 [00:03<00:16, 33371.61it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  20%|█▉        | 134144/677372 [00:03<00:23, 22814.77it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  20%|██        | 137216/677372 [00:04<00:22, 23763.35it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  21%|██        | 140288/677372 [00:04<00:21, 24612.37it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  21%|██▏       | 144384/677372 [00:04<00:18, 28105.38it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  22%|██▏       | 149504/677372 [00:04<00:16, 31873.21it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  23%|██▎       | 154624/677372 [00:04<00:15, 34474.46it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  23%|██▎       | 158720/677372 [00:04<00:14, 35939.72it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  24%|██▍       | 163840/677372 [00:04<00:13, 39284.31it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  25%|██▍       | 168960/677372 [00:04<00:12, 40821.43it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  26%|██▌       | 173439/677372 [00:05<00:23, 21399.92it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  26%|██▌       | 177535/677372 [00:05<00:21, 23637.68it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  27%|██▋       | 181631/677372 [00:05<00:19, 24907.06it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  27%|██▋       | 185727/677372 [00:05<00:19, 25820.14it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  28%|██▊       | 188799/677372 [00:05<00:20, 24027.49it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  28%|██▊       | 191871/677372 [00:06<00:20, 24228.20it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  29%|██▉       | 194943/677372 [00:06<00:19, 24646.37it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  29%|██▉       | 199039/677372 [00:06<00:17, 26926.13it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  30%|██▉       | 203135/677372 [00:06<00:16, 29342.39it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  31%|███       | 207231/677372 [00:06<00:15, 30909.50it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  31%|███       | 211327/677372 [00:06<00:17, 27260.29it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  32%|███▏      | 214399/677372 [00:06<00:20, 22800.40it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  32%|███▏      | 217471/677372 [00:07<00:22, 20580.53it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  33%|███▎      | 221567/677372 [00:07<00:18, 24208.17it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  33%|███▎      | 225663/677372 [00:07<00:16, 27276.69it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  34%|███▍      | 229759/677372 [00:07<00:15, 29118.99it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  35%|███▍      | 233855/677372 [00:07<00:15, 29357.45it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  35%|███▌      | 237951/677372 [00:07<00:15, 27513.01it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  36%|███▌      | 241023/677372 [00:07<00:15, 27690.50it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  36%|███▌      | 245119/677372 [00:07<00:14, 29310.25it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  37%|███▋      | 249215/677372 [00:08<00:13, 31788.08it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  37%|███▋      | 253311/677372 [00:08<00:12, 32831.03it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  38%|███▊      | 257407/677372 [00:08<00:12, 32398.08it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  39%|███▊      | 261503/677372 [00:08<00:12, 32048.05it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  39%|███▉      | 265599/677372 [00:08<00:13, 31386.14it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  40%|███▉      | 269695/677372 [00:08<00:14, 28481.11it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  40%|████      | 273791/677372 [00:08<00:13, 30265.76it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  41%|████      | 277887/677372 [00:09<00:12, 31242.93it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  42%|████▏     | 281983/677372 [00:09<00:11, 32960.24it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  42%|████▏     | 286079/677372 [00:09<00:11, 33248.18it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  43%|████▎     | 290175/677372 [00:09<00:11, 32855.01it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  43%|████▎     | 294271/677372 [00:09<00:11, 33601.79it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  44%|████▍     | 298367/677372 [00:09<00:11, 32223.70it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  45%|████▍     | 302463/677372 [00:09<00:14, 26135.25it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  45%|████▌     | 305535/677372 [00:10<00:16, 22520.45it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  46%|████▌     | 308607/677372 [00:10<00:16, 22412.92it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  46%|████▌     | 312703/677372 [00:10<00:15, 24183.92it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  47%|████▋     | 315775/677372 [00:10<00:14, 25319.51it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  47%|████▋     | 318847/677372 [00:10<00:16, 21697.70it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  48%|████▊     | 321919/677372 [00:10<00:15, 22868.77it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  48%|████▊     | 324991/677372 [00:10<00:14, 24435.45it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  49%|████▊     | 329087/677372 [00:10<00:12, 26925.49it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  49%|████▉     | 333183/677372 [00:11<00:12, 28377.67it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  50%|████▉     | 337279/677372 [00:11<00:11, 29577.18it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  50%|█████     | 340734/677372 [00:11<00:25, 13383.10it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  51%|█████     | 344830/677372 [00:11<00:20, 16606.30it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  52%|█████▏    | 348926/677372 [00:12<00:16, 19634.57it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  52%|█████▏    | 353022/677372 [00:12<00:14, 22634.61it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  53%|█████▎    | 357118/677372 [00:12<00:12, 25786.79it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  53%|█████▎    | 361214/677372 [00:12<00:11, 26443.04it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  54%|█████▍    | 365310/677372 [00:12<00:12, 25110.77it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  55%|█████▍    | 369406/677372 [00:12<00:11, 27649.97it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  55%|█████▌    | 373502/677372 [00:12<00:10, 29788.88it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  56%|█████▌    | 377598/677372 [00:12<00:09, 31172.29it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  56%|█████▋    | 381694/677372 [00:13<00:09, 32276.03it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  57%|█████▋    | 385790/677372 [00:13<00:09, 31359.02it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  58%|█████▊    | 389886/677372 [00:13<00:09, 30965.27it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  58%|█████▊    | 393982/677372 [00:13<00:09, 30053.62it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  59%|█████▊    | 397054/677372 [00:13<00:09, 29794.96it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  59%|█████▉    | 400126/677372 [00:13<00:10, 27440.28it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  60%|█████▉    | 403198/677372 [00:13<00:10, 26005.46it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  60%|█████▉    | 406270/677372 [00:14<00:11, 24420.87it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  60%|██████    | 409342/677372 [00:14<00:10, 25697.27it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  61%|██████    | 413438/677372 [00:14<00:09, 28419.10it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  61%|██████▏   | 416510/677372 [00:14<00:09, 28680.69it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  62%|██████▏   | 420606/677372 [00:14<00:08, 29147.43it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  63%|██████▎   | 423678/677372 [00:14<00:08, 29212.94it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  63%|██████▎   | 426750/677372 [00:14<00:08, 28098.09it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  63%|██████▎   | 429822/677372 [00:14<00:08, 28732.17it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  64%|██████▍   | 432894/677372 [00:14<00:09, 27044.63it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  65%|██████▍   | 436990/677372 [00:15<00:08, 28274.58it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  65%|██████▌   | 441086/677372 [00:15<00:08, 28876.04it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  66%|██████▌   | 445182/677372 [00:15<00:07, 29731.60it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  66%|██████▌   | 448254/677372 [00:15<00:07, 29446.33it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  67%|██████▋   | 451326/677372 [00:15<00:08, 28048.59it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  67%|██████▋   | 454398/677372 [00:15<00:09, 22692.15it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  68%|██████▊   | 457470/677372 [00:16<00:12, 17041.91it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  68%|██████▊   | 459518/677372 [00:16<00:14, 15523.80it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  68%|██████▊   | 461566/677372 [00:16<00:13, 15904.70it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  69%|██████▊   | 464638/677372 [00:16<00:11, 18126.06it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  69%|██████▉   | 468734/677372 [00:16<00:09, 21736.05it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  70%|██████▉   | 471806/677372 [00:16<00:08, 23708.68it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  70%|███████   | 474878/677372 [00:16<00:08, 22820.59it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  71%|███████   | 477950/677372 [00:16<00:08, 24171.41it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  71%|███████   | 482046/677372 [00:17<00:07, 26470.60it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  72%|███████▏  | 486142/677372 [00:17<00:06, 27811.10it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  72%|███████▏  | 490238/677372 [00:17<00:06, 29556.85it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  73%|███████▎  | 494334/677372 [00:17<00:06, 30425.44it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  74%|███████▎  | 498430/677372 [00:17<00:05, 30561.13it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  74%|███████▍  | 502526/677372 [00:17<00:05, 31550.60it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  75%|███████▍  | 506622/677372 [00:17<00:05, 28678.05it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  75%|███████▌  | 510077/677372 [00:18<00:12, 13490.30it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  76%|███████▌  | 515197/677372 [00:18<00:08, 18346.08it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  77%|███████▋  | 519293/677372 [00:18<00:07, 21678.95it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  78%|███████▊  | 525437/677372 [00:18<00:05, 28087.27it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  78%|███████▊  | 530557/677372 [00:18<00:04, 31427.55it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  79%|███████▉  | 534653/677372 [00:19<00:04, 31285.08it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  80%|███████▉  | 539773/677372 [00:19<00:03, 34689.16it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  80%|████████  | 544893/677372 [00:19<00:03, 36968.54it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  81%|████████  | 550013/677372 [00:19<00:03, 39716.96it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  82%|████████▏ | 555133/677372 [00:19<00:04, 27837.61it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  83%|████████▎ | 559229/677372 [00:19<00:04, 25614.87it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  83%|████████▎ | 562301/677372 [00:20<00:07, 16015.84it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  83%|████████▎ | 565373/677372 [00:20<00:08, 13492.96it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  84%|████████▍ | 567421/677372 [00:20<00:08, 13333.11it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  84%|████████▍ | 569469/677372 [00:21<00:08, 12985.10it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  85%|████████▍ | 573565/677372 [00:21<00:06, 17094.97it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  85%|████████▌ | 576637/677372 [00:21<00:05, 18778.90it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  86%|████████▌ | 579709/677372 [00:21<00:05, 18343.80it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  86%|████████▌ | 583805/677372 [00:21<00:04, 22563.57it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  87%|████████▋ | 587901/677372 [00:21<00:03, 26346.32it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  87%|████████▋ | 590973/677372 [00:21<00:03, 26725.28it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  88%|████████▊ | 595069/677372 [00:21<00:02, 28966.00it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  88%|████████▊ | 599165/677372 [00:22<00:02, 30401.73it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  89%|████████▉ | 604285/677372 [00:22<00:02, 35030.35it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  90%|████████▉ | 608381/677372 [00:22<00:02, 33721.80it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  91%|█████████ | 614525/677372 [00:22<00:01, 39041.06it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  91%|█████████▏| 618621/677372 [00:22<00:01, 39195.99it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  92%|█████████▏| 623741/677372 [00:22<00:01, 38352.14it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  93%|█████████▎| 628861/677372 [00:22<00:01, 39423.39it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  94%|█████████▎| 635005/677372 [00:22<00:00, 43069.69it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  95%|█████████▍| 640125/677372 [00:23<00:00, 44927.18it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  95%|█████████▌| 646269/677372 [00:23<00:00, 47704.43it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  96%|█████████▋| 652413/677372 [00:23<00:00, 50345.50it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  97%|█████████▋| 657533/677372 [00:23<00:00, 48825.37it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  98%|█████████▊| 662653/677372 [00:23<00:00, 47032.89it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  99%|█████████▊| 667773/677372 [00:23<00:00, 27865.87it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  99%|█████████▉| 671869/677372 [00:23<00:00, 28465.10it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating: 100%|██████████| 677372/677372 [00:24<00:00, 27709.45it/s]\u001B[A\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, Train: 0.4934, Val: 0.4954, Test: 0.4397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/90941 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:   0%|          | 0/90941 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:   1%|          | 1024/90941 [00:04<06:41, 224.14it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:   2%|▏         | 2048/90941 [00:06<04:29, 329.34it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:   3%|▎         | 3072/90941 [00:08<03:40, 397.69it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:   5%|▍         | 4096/90941 [00:10<03:06, 466.80it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:   6%|▌         | 5120/90941 [00:12<02:55, 489.08it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:   7%|▋         | 6144/90941 [00:13<02:41, 523.99it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:   8%|▊         | 7168/90941 [00:15<02:43, 512.47it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:   9%|▉         | 8192/90941 [00:18<02:58, 463.41it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  10%|█         | 9216/90941 [00:20<02:57, 460.90it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  11%|█▏        | 10240/90941 [00:22<02:36, 516.36it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  12%|█▏        | 11264/90941 [00:23<02:26, 543.19it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  14%|█▎        | 12288/90941 [00:25<02:28, 531.24it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  15%|█▍        | 13312/90941 [00:27<02:14, 576.17it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  16%|█▌        | 14336/90941 [00:28<02:04, 613.54it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  17%|█▋        | 15360/90941 [00:30<02:01, 620.97it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  18%|█▊        | 16384/90941 [00:31<01:57, 633.55it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  19%|█▉        | 17408/90941 [00:33<01:52, 654.64it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  20%|██        | 18432/90941 [00:34<01:45, 687.90it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  21%|██▏       | 19456/90941 [00:36<01:53, 627.57it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  23%|██▎       | 20480/90941 [00:38<01:50, 637.42it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  24%|██▎       | 21504/90941 [00:39<01:51, 622.16it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  25%|██▍       | 22528/90941 [00:41<01:42, 667.36it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  26%|██▌       | 23552/90941 [00:42<01:40, 671.66it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  27%|██▋       | 24576/90941 [00:43<01:32, 717.97it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  28%|██▊       | 25600/90941 [00:45<01:28, 736.66it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  29%|██▉       | 26624/90941 [00:46<01:30, 708.40it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  30%|███       | 27648/90941 [00:47<01:24, 747.86it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  32%|███▏      | 28672/90941 [00:49<01:27, 715.33it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  33%|███▎      | 29696/90941 [00:51<01:33, 653.78it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  34%|███▍      | 30720/90941 [00:52<01:27, 691.75it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  35%|███▍      | 31744/90941 [00:54<01:27, 676.82it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  36%|███▌      | 32768/90941 [00:55<01:24, 689.40it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  37%|███▋      | 33792/90941 [00:57<01:20, 710.74it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  38%|███▊      | 34816/90941 [00:58<01:24, 663.30it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  39%|███▉      | 35840/90941 [01:00<01:24, 655.27it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  41%|████      | 36864/90941 [01:02<01:27, 620.68it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  42%|████▏     | 37888/90941 [01:03<01:25, 621.35it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  43%|████▎     | 38912/90941 [01:05<01:25, 609.23it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  44%|████▍     | 39936/90941 [01:07<01:24, 600.61it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  45%|████▌     | 40960/90941 [01:08<01:20, 622.40it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  46%|████▌     | 41984/90941 [01:11<01:24, 576.49it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  47%|████▋     | 43008/90941 [01:12<01:18, 614.22it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  48%|████▊     | 44032/90941 [01:13<01:11, 652.97it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  50%|████▉     | 45056/90941 [01:15<01:07, 681.23it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  51%|█████     | 46080/90941 [01:17<01:13, 609.70it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  52%|█████▏    | 47104/90941 [01:18<01:06, 656.25it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  53%|█████▎    | 48128/90941 [01:20<01:04, 667.84it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  54%|█████▍    | 49152/90941 [01:21<00:59, 698.78it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  55%|█████▌    | 50176/90941 [01:22<01:00, 672.75it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  56%|█████▋    | 51200/90941 [01:24<00:56, 706.00it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  57%|█████▋    | 52224/90941 [01:25<00:55, 703.94it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  59%|█████▊    | 53248/90941 [01:27<00:52, 714.47it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  60%|█████▉    | 54272/90941 [01:28<00:51, 717.90it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  61%|██████    | 55296/90941 [01:30<00:50, 705.79it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  62%|██████▏   | 56320/90941 [01:31<00:50, 686.06it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  63%|██████▎   | 57344/90941 [01:33<00:47, 700.40it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  64%|██████▍   | 58368/90941 [01:34<00:47, 692.46it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  65%|██████▌   | 59392/90941 [01:35<00:45, 694.44it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  66%|██████▋   | 60416/90941 [01:37<00:41, 737.12it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  68%|██████▊   | 61440/90941 [01:38<00:39, 742.99it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  69%|██████▊   | 62464/90941 [01:40<00:42, 667.79it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  70%|██████▉   | 63488/90941 [01:42<00:43, 637.08it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  71%|███████   | 64512/90941 [01:43<00:41, 644.17it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  72%|███████▏  | 65536/90941 [01:45<00:37, 669.45it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  73%|███████▎  | 66560/90941 [01:46<00:36, 658.97it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  74%|███████▍  | 67584/90941 [01:48<00:34, 679.87it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  75%|███████▌  | 68608/90941 [01:49<00:32, 692.38it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  77%|███████▋  | 69632/90941 [01:50<00:29, 711.53it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  78%|███████▊  | 70656/90941 [01:52<00:28, 710.79it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  79%|███████▉  | 71680/90941 [01:53<00:28, 686.35it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  80%|███████▉  | 72704/90941 [01:55<00:26, 699.99it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  81%|████████  | 73728/90941 [01:56<00:24, 690.20it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  82%|████████▏ | 74752/90941 [01:58<00:23, 674.88it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  83%|████████▎ | 75776/90941 [02:00<00:22, 668.16it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  84%|████████▍ | 76800/90941 [02:01<00:22, 626.61it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  86%|████████▌ | 77824/90941 [02:05<00:30, 435.42it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  87%|████████▋ | 78848/90941 [02:07<00:26, 455.69it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  88%|████████▊ | 79872/90941 [02:09<00:23, 474.85it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  89%|████████▉ | 80896/90941 [02:11<00:19, 519.25it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  90%|█████████ | 81920/90941 [02:12<00:16, 554.84it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  91%|█████████ | 82944/90941 [02:14<00:13, 595.08it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  92%|█████████▏| 83968/90941 [02:15<00:11, 631.27it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  93%|█████████▎| 84992/90941 [02:17<00:09, 640.77it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  95%|█████████▍| 86016/90941 [02:18<00:07, 651.00it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  96%|█████████▌| 87040/90941 [02:20<00:05, 682.75it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  97%|█████████▋| 88064/90941 [02:21<00:04, 710.04it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  98%|█████████▊| 89088/90941 [02:23<00:02, 653.74it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02:  99%|█████████▉| 90112/90941 [02:24<00:01, 696.98it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 02: 100%|██████████| 90941/90941 [02:26<00:00, 622.65it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/677372 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   0%|          | 0/677372 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   0%|          | 1024/677372 [00:00<02:03, 5470.03it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   1%|          | 4096/677372 [00:00<00:41, 16340.17it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   1%|▏         | 9216/677372 [00:00<00:22, 29619.33it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   2%|▏         | 13312/677372 [00:00<00:20, 32777.13it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   3%|▎         | 18432/677372 [00:00<00:17, 36779.64it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   3%|▎         | 23552/677372 [00:00<00:16, 40043.12it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   4%|▍         | 28672/677372 [00:00<00:15, 40900.98it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   5%|▍         | 33792/677372 [00:00<00:15, 42115.57it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   6%|▌         | 38912/677372 [00:01<00:18, 34758.32it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   6%|▋         | 43008/677372 [00:01<00:20, 30482.01it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   7%|▋         | 47104/677372 [00:01<00:21, 28690.39it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   8%|▊         | 52224/677372 [00:01<00:19, 32181.68it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   8%|▊         | 57344/677372 [00:01<00:17, 35243.82it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   9%|▉         | 62464/677372 [00:01<00:16, 38393.62it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  10%|▉         | 67584/677372 [00:01<00:15, 39770.68it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  11%|█         | 72704/677372 [00:02<00:15, 39177.23it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  11%|█▏        | 76800/677372 [00:02<00:15, 38837.99it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  12%|█▏        | 80896/677372 [00:02<00:15, 37606.50it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  13%|█▎        | 86016/677372 [00:02<00:15, 39363.40it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  13%|█▎        | 90112/677372 [00:02<00:14, 39630.72it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  14%|█▍        | 94208/677372 [00:02<00:14, 39933.35it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  15%|█▍        | 98304/677372 [00:02<00:15, 38005.58it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  15%|█▌        | 102400/677372 [00:02<00:15, 37959.64it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  16%|█▌        | 106496/677372 [00:02<00:15, 37358.93it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  16%|█▋        | 111616/677372 [00:03<00:14, 38635.13it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  17%|█▋        | 116736/677372 [00:03<00:13, 41055.08it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  18%|█▊        | 121856/677372 [00:03<00:13, 42149.98it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  19%|█▊        | 126976/677372 [00:03<00:13, 41497.85it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  20%|█▉        | 132096/677372 [00:03<00:13, 39316.82it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  20%|██        | 137216/677372 [00:03<00:12, 42088.24it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  21%|██        | 143360/677372 [00:03<00:11, 45068.50it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  22%|██▏       | 148480/677372 [00:03<00:12, 43501.30it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  23%|██▎       | 153600/677372 [00:04<00:12, 42383.26it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  23%|██▎       | 158720/677372 [00:04<00:12, 40167.44it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  24%|██▍       | 163840/677372 [00:04<00:11, 42848.58it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  25%|██▍       | 168960/677372 [00:04<00:11, 44050.69it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  26%|██▌       | 173439/677372 [00:04<00:21, 23239.39it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  26%|██▌       | 177535/677372 [00:04<00:19, 25373.98it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  27%|██▋       | 181631/677372 [00:05<00:18, 27338.90it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  27%|██▋       | 185727/677372 [00:05<00:16, 29691.02it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  28%|██▊       | 190847/677372 [00:05<00:14, 33287.58it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  29%|██▉       | 194943/677372 [00:05<00:15, 30761.05it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  29%|██▉       | 199039/677372 [00:05<00:14, 31947.65it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  30%|██▉       | 203135/677372 [00:05<00:13, 34092.05it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  31%|███       | 207231/677372 [00:05<00:13, 34797.08it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  31%|███       | 211327/677372 [00:05<00:14, 31811.95it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  32%|███▏      | 215423/677372 [00:06<00:15, 29390.51it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  32%|███▏      | 219519/677372 [00:06<00:15, 30478.15it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  33%|███▎      | 223615/677372 [00:06<00:14, 32230.01it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  34%|███▎      | 227711/677372 [00:06<00:13, 33419.38it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  34%|███▍      | 231807/677372 [00:06<00:13, 34097.61it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  35%|███▍      | 235903/677372 [00:06<00:12, 34264.73it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  35%|███▌      | 239999/677372 [00:07<00:24, 18015.17it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  36%|███▌      | 243071/677372 [00:07<00:44, 9788.00it/s] \u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  36%|███▌      | 245119/677372 [00:08<00:40, 10799.93it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  37%|███▋      | 248191/677372 [00:08<00:32, 13262.82it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  37%|███▋      | 252287/677372 [00:08<00:24, 17062.97it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  38%|███▊      | 256383/677372 [00:08<00:20, 20335.76it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  38%|███▊      | 259455/677372 [00:08<00:18, 22162.53it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  39%|███▉      | 263551/677372 [00:08<00:17, 24325.87it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  40%|███▉      | 267647/677372 [00:08<00:15, 26716.16it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  40%|████      | 271743/677372 [00:08<00:13, 29322.48it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  41%|████      | 275839/677372 [00:09<00:13, 29166.93it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  41%|████▏     | 279935/677372 [00:09<00:13, 28479.65it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  42%|████▏     | 283007/677372 [00:09<00:13, 28429.73it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  42%|████▏     | 287103/677372 [00:09<00:13, 30000.27it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  43%|████▎     | 291199/677372 [00:09<00:13, 29601.54it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  44%|████▎     | 295295/677372 [00:09<00:12, 29903.18it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  44%|████▍     | 299391/677372 [00:09<00:12, 30546.90it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  45%|████▍     | 303487/677372 [00:09<00:12, 28845.64it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  45%|████▌     | 306559/677372 [00:10<00:13, 27168.77it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  46%|████▌     | 309631/677372 [00:10<00:14, 26212.74it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  46%|████▌     | 312703/677372 [00:10<00:13, 26547.92it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  47%|████▋     | 315775/677372 [00:10<00:13, 27299.07it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  47%|████▋     | 319871/677372 [00:10<00:12, 29438.69it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  48%|████▊     | 322943/677372 [00:10<00:12, 29427.24it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  48%|████▊     | 326015/677372 [00:10<00:12, 27336.03it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  49%|████▊     | 329087/677372 [00:10<00:12, 27842.75it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  49%|████▉     | 332159/677372 [00:11<00:12, 27210.76it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  49%|████▉     | 335231/677372 [00:11<00:15, 21692.32it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  50%|████▉     | 338303/677372 [00:11<00:17, 19732.45it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  50%|█████     | 340734/677372 [00:12<00:34, 9743.51it/s] \u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  51%|█████     | 343806/677372 [00:12<00:27, 12076.65it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  51%|█████     | 346878/677372 [00:12<00:23, 14246.07it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  52%|█████▏    | 349950/677372 [00:12<00:19, 16562.64it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  52%|█████▏    | 353022/677372 [00:12<00:17, 18924.95it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  53%|█████▎    | 356094/677372 [00:12<00:15, 20999.48it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  53%|█████▎    | 359166/677372 [00:12<00:14, 22065.64it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  53%|█████▎    | 362238/677372 [00:13<00:17, 17870.26it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  54%|█████▍    | 365310/677372 [00:13<00:17, 18009.73it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  55%|█████▍    | 369406/677372 [00:13<00:13, 22074.21it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  55%|█████▌    | 373502/677372 [00:13<00:11, 26074.26it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  56%|█████▌    | 377598/677372 [00:13<00:10, 28275.11it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  56%|█████▋    | 381694/677372 [00:13<00:09, 30667.60it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  57%|█████▋    | 385790/677372 [00:13<00:08, 33034.64it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  58%|█████▊    | 389886/677372 [00:13<00:08, 34436.99it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  58%|█████▊    | 393982/677372 [00:13<00:08, 32918.11it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  59%|█████▉    | 398078/677372 [00:14<00:09, 30355.72it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  59%|█████▉    | 402174/677372 [00:14<00:09, 29741.17it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  60%|█████▉    | 405246/677372 [00:14<00:09, 29896.30it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  60%|██████    | 408318/677372 [00:14<00:10, 26113.40it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  61%|██████    | 411390/677372 [00:14<00:10, 24389.19it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  61%|██████    | 414462/677372 [00:14<00:11, 23522.57it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  62%|██████▏   | 417534/677372 [00:14<00:10, 24337.05it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  62%|██████▏   | 420606/677372 [00:15<00:10, 24306.68it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  63%|██████▎   | 423678/677372 [00:15<00:14, 17217.24it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  63%|██████▎   | 425726/677372 [00:15<00:16, 15288.85it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  63%|██████▎   | 428798/677372 [00:15<00:14, 17535.09it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  64%|██████▍   | 431870/677372 [00:15<00:13, 18216.65it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  64%|██████▍   | 433918/677372 [00:15<00:14, 17156.77it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  64%|██████▍   | 435966/677372 [00:16<00:15, 15955.06it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  65%|██████▍   | 439038/677372 [00:16<00:13, 17488.86it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  65%|██████▌   | 443134/677372 [00:16<00:10, 21769.80it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  66%|██████▌   | 446206/677372 [00:16<00:09, 23394.14it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  66%|██████▋   | 450302/677372 [00:16<00:08, 26401.08it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  67%|██████▋   | 454398/677372 [00:16<00:07, 28099.63it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  68%|██████▊   | 458494/677372 [00:16<00:07, 30693.43it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  68%|██████▊   | 462590/677372 [00:17<00:07, 29287.17it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  69%|██████▊   | 465662/677372 [00:17<00:07, 28368.88it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  69%|██████▉   | 468734/677372 [00:17<00:08, 24788.21it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  70%|██████▉   | 472830/677372 [00:17<00:07, 27038.16it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  70%|███████   | 476926/677372 [00:17<00:06, 28890.71it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  71%|███████   | 481022/677372 [00:17<00:06, 30277.76it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  72%|███████▏  | 485118/677372 [00:17<00:06, 30473.04it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  72%|███████▏  | 489214/677372 [00:17<00:06, 29989.73it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  73%|███████▎  | 493310/677372 [00:18<00:06, 29424.70it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  73%|███████▎  | 496382/677372 [00:18<00:06, 28752.95it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  74%|███████▎  | 499454/677372 [00:18<00:06, 27923.32it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  74%|███████▍  | 502526/677372 [00:18<00:06, 28335.45it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  75%|███████▍  | 505598/677372 [00:18<00:06, 28286.39it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  75%|███████▌  | 509053/677372 [00:19<00:14, 11591.24it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  76%|███████▌  | 512125/677372 [00:19<00:13, 12294.34it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  76%|███████▌  | 516221/677372 [00:19<00:10, 16078.86it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  77%|███████▋  | 521341/677372 [00:19<00:07, 21773.74it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  78%|███████▊  | 526461/677372 [00:19<00:05, 26833.81it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  78%|███████▊  | 530557/677372 [00:19<00:04, 29688.76it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  79%|███████▉  | 534653/677372 [00:19<00:04, 30723.21it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  80%|███████▉  | 539773/677372 [00:20<00:03, 34960.29it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  80%|████████  | 543869/677372 [00:20<00:04, 31626.88it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  81%|████████  | 548989/677372 [00:20<00:03, 35462.10it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  82%|████████▏ | 554109/677372 [00:20<00:03, 36838.95it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  82%|████████▏ | 558205/677372 [00:20<00:03, 36163.33it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  83%|████████▎ | 564349/677372 [00:20<00:02, 40803.82it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  84%|████████▍ | 569469/677372 [00:20<00:02, 43205.97it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  85%|████████▍ | 575613/677372 [00:20<00:02, 41087.18it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  86%|████████▌ | 580733/677372 [00:21<00:02, 41416.99it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  86%|████████▋ | 585853/677372 [00:21<00:02, 38112.32it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  87%|████████▋ | 589949/677372 [00:21<00:03, 26807.43it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  88%|████████▊ | 594045/677372 [00:21<00:02, 29276.37it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  88%|████████▊ | 599165/677372 [00:21<00:02, 33268.04it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  89%|████████▉ | 605309/677372 [00:21<00:01, 39151.97it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  90%|█████████ | 611453/677372 [00:21<00:01, 43445.54it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  91%|█████████ | 616573/677372 [00:22<00:01, 44400.75it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  92%|█████████▏| 621693/677372 [00:22<00:02, 21439.11it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  93%|█████████▎| 626813/677372 [00:22<00:02, 25101.29it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  93%|█████████▎| 632957/677372 [00:22<00:01, 30515.72it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  94%|█████████▍| 638077/677372 [00:22<00:01, 33907.45it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  95%|█████████▍| 643197/677372 [00:23<00:00, 34322.56it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  96%|█████████▌| 648317/677372 [00:23<00:00, 31389.23it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  97%|█████████▋| 654461/677372 [00:23<00:00, 36786.12it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  98%|█████████▊| 661629/677372 [00:23<00:00, 43621.39it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  99%|█████████▊| 668797/677372 [00:23<00:00, 49752.81it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating: 100%|██████████| 677372/677372 [00:23<00:00, 28331.91it/s]\u001B[A\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02, Train: 0.5672, Val: 0.5475, Test: 0.4870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/90941 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:   0%|          | 0/90941 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:   1%|          | 1024/90941 [00:02<03:10, 473.24it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:   2%|▏         | 2048/90941 [00:03<02:27, 604.27it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:   3%|▎         | 3072/90941 [00:04<02:06, 694.12it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:   5%|▍         | 4096/90941 [00:06<02:08, 673.89it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:   6%|▌         | 5120/90941 [00:07<02:07, 673.69it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:   7%|▋         | 6144/90941 [00:09<02:15, 624.48it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:   8%|▊         | 7168/90941 [00:10<02:03, 676.71it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:   9%|▉         | 8192/90941 [00:12<02:08, 642.63it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  10%|█         | 9216/90941 [00:14<02:12, 617.75it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  11%|█▏        | 10240/90941 [00:16<02:10, 619.90it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  12%|█▏        | 11264/90941 [00:17<02:03, 646.55it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  14%|█▎        | 12288/90941 [00:19<02:02, 640.60it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  15%|█▍        | 13312/90941 [00:21<02:08, 605.36it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  16%|█▌        | 14336/90941 [00:23<02:12, 576.26it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  17%|█▋        | 15360/90941 [00:24<02:11, 576.32it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  18%|█▊        | 16384/90941 [00:27<02:21, 528.69it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  19%|█▉        | 17408/90941 [00:29<02:20, 521.68it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  20%|██        | 18432/90941 [00:31<02:21, 511.16it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  21%|██▏       | 19456/90941 [00:33<02:20, 507.29it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  23%|██▎       | 20480/90941 [00:34<02:08, 550.33it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  24%|██▎       | 21504/90941 [00:36<02:01, 571.29it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  25%|██▍       | 22528/90941 [00:38<02:11, 520.53it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  26%|██▌       | 23552/90941 [00:40<02:05, 537.66it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  27%|██▋       | 24576/90941 [00:42<01:58, 557.84it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  28%|██▊       | 25600/90941 [00:43<01:52, 583.39it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  29%|██▉       | 26624/90941 [00:45<01:47, 599.31it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  30%|███       | 27648/90941 [00:46<01:39, 639.02it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  32%|███▏      | 28672/90941 [00:48<01:30, 687.32it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  33%|███▎      | 29696/90941 [00:49<01:22, 742.84it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  34%|███▍      | 30720/90941 [00:50<01:19, 753.07it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  35%|███▍      | 31744/90941 [00:52<01:26, 683.10it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  36%|███▌      | 32768/90941 [00:53<01:23, 693.05it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  37%|███▋      | 33792/90941 [00:55<01:21, 702.42it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  38%|███▊      | 34816/90941 [00:56<01:16, 734.33it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  39%|███▉      | 35840/90941 [00:57<01:11, 770.50it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  41%|████      | 36864/90941 [00:58<01:04, 837.94it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  42%|████▏     | 37888/90941 [00:59<01:01, 868.67it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  43%|████▎     | 38912/90941 [01:00<00:59, 871.63it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  44%|████▍     | 39936/90941 [01:02<01:03, 805.47it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  45%|████▌     | 40960/90941 [01:03<01:00, 830.82it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  46%|████▌     | 41984/90941 [01:04<00:57, 845.67it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  47%|████▋     | 43008/90941 [01:05<00:57, 833.89it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  48%|████▊     | 44032/90941 [01:07<01:02, 745.04it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  50%|████▉     | 45056/90941 [01:08<01:00, 756.52it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  51%|█████     | 46080/90941 [01:10<00:59, 758.27it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  52%|█████▏    | 47104/90941 [01:11<00:54, 808.67it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  53%|█████▎    | 48128/90941 [01:12<00:51, 836.48it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  54%|█████▍    | 49152/90941 [01:13<00:54, 773.44it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  55%|█████▌    | 50176/90941 [01:15<00:51, 791.87it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  56%|█████▋    | 51200/90941 [01:16<00:50, 791.07it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  57%|█████▋    | 52224/90941 [01:17<00:48, 792.59it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  59%|█████▊    | 53248/90941 [01:18<00:46, 809.05it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  60%|█████▉    | 54272/90941 [01:20<00:44, 828.07it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  61%|██████    | 55296/90941 [01:21<00:43, 823.52it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  62%|██████▏   | 56320/90941 [01:22<00:43, 801.71it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  63%|██████▎   | 57344/90941 [01:23<00:39, 853.62it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  64%|██████▍   | 58368/90941 [01:24<00:36, 883.89it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  65%|██████▌   | 59392/90941 [01:25<00:34, 917.83it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  66%|██████▋   | 60416/90941 [01:27<00:34, 896.06it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  68%|██████▊   | 61440/90941 [01:28<00:33, 875.11it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  69%|██████▊   | 62464/90941 [01:29<00:31, 893.34it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  70%|██████▉   | 63488/90941 [01:30<00:30, 906.28it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  71%|███████   | 64512/90941 [01:31<00:28, 913.55it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  72%|███████▏  | 65536/90941 [01:32<00:27, 932.25it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  73%|███████▎  | 66560/90941 [01:33<00:25, 947.71it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  74%|███████▍  | 67584/90941 [01:34<00:24, 941.28it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  75%|███████▌  | 68608/90941 [01:35<00:23, 947.73it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  77%|███████▋  | 69632/90941 [01:36<00:22, 931.26it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  78%|███████▊  | 70656/90941 [01:38<00:21, 937.21it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  79%|███████▉  | 71680/90941 [01:39<00:20, 948.44it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  80%|███████▉  | 72704/90941 [01:40<00:19, 924.83it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  81%|████████  | 73728/90941 [01:41<00:19, 870.37it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  82%|████████▏ | 74752/90941 [01:42<00:18, 889.30it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  83%|████████▎ | 75776/90941 [01:43<00:16, 902.33it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  84%|████████▍ | 76800/90941 [01:44<00:15, 932.87it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  86%|████████▌ | 77824/90941 [01:46<00:15, 834.42it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  87%|████████▋ | 78848/90941 [01:47<00:14, 861.12it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  88%|████████▊ | 79872/90941 [01:48<00:12, 907.97it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  89%|████████▉ | 80896/90941 [01:49<00:11, 895.20it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  90%|█████████ | 81920/90941 [01:50<00:09, 920.77it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  91%|█████████ | 82944/90941 [01:51<00:08, 893.97it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  92%|█████████▏| 83968/90941 [01:52<00:07, 904.20it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  93%|█████████▎| 84992/90941 [01:54<00:06, 930.60it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  95%|█████████▍| 86016/90941 [01:54<00:05, 965.40it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  96%|█████████▌| 87040/90941 [01:56<00:04, 874.26it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  97%|█████████▋| 88064/90941 [01:57<00:03, 909.01it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  98%|█████████▊| 89088/90941 [01:58<00:01, 927.30it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03:  99%|█████████▉| 90112/90941 [01:59<00:00, 934.99it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 03: 100%|██████████| 90941/90941 [02:00<00:00, 754.24it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/677372 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   0%|          | 0/677372 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   0%|          | 1024/677372 [00:00<02:07, 5306.57it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   1%|          | 5120/677372 [00:00<00:35, 19108.50it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   1%|          | 8192/677372 [00:00<00:43, 15368.46it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   2%|▏         | 11264/677372 [00:00<00:36, 18252.37it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   2%|▏         | 15360/677372 [00:00<00:27, 24037.47it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   3%|▎         | 19456/677372 [00:00<00:23, 27448.97it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   3%|▎         | 23552/677372 [00:01<00:22, 29343.51it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   4%|▍         | 27648/677372 [00:01<00:20, 32292.70it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   5%|▍         | 33792/677372 [00:01<00:16, 39389.59it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   6%|▌         | 38912/677372 [00:01<00:15, 42002.24it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   7%|▋         | 44032/677372 [00:01<00:14, 44190.84it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   7%|▋         | 49152/677372 [00:01<00:14, 43361.91it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   8%|▊         | 54272/677372 [00:01<00:13, 44660.93it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:   9%|▉         | 59392/677372 [00:01<00:13, 45467.32it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  10%|▉         | 64512/677372 [00:01<00:13, 45720.79it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  10%|█         | 69632/677372 [00:01<00:13, 45733.71it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  11%|█         | 74752/677372 [00:02<00:13, 45436.71it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  12%|█▏        | 79872/677372 [00:02<00:12, 46467.72it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  13%|█▎        | 86016/677372 [00:02<00:12, 48465.38it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  13%|█▎        | 91136/677372 [00:02<00:12, 47815.33it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  14%|█▍        | 96256/677372 [00:02<00:12, 47928.60it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  15%|█▍        | 101376/677372 [00:02<00:11, 48607.69it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  16%|█▌        | 106496/677372 [00:02<00:11, 48395.63it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  16%|█▋        | 111616/677372 [00:02<00:11, 48838.17it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  17%|█▋        | 116736/677372 [00:02<00:11, 48934.89it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  18%|█▊        | 121856/677372 [00:03<00:11, 48857.63it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  19%|█▊        | 126976/677372 [00:03<00:11, 48198.24it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  20%|█▉        | 132096/677372 [00:03<00:11, 48765.83it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  20%|██        | 138240/677372 [00:03<00:10, 50825.31it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  21%|██▏       | 144384/677372 [00:03<00:10, 53189.81it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  22%|██▏       | 150528/677372 [00:03<00:09, 52802.46it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  23%|██▎       | 156672/677372 [00:03<00:09, 53602.94it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  24%|██▍       | 162816/677372 [00:03<00:09, 54233.66it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  25%|██▍       | 168960/677372 [00:03<00:09, 53332.31it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  26%|██▌       | 174463/677372 [00:04<00:16, 30012.34it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  27%|██▋       | 180607/677372 [00:04<00:14, 35099.13it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  28%|██▊       | 186751/677372 [00:04<00:12, 39290.71it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  28%|██▊       | 191871/677372 [00:04<00:11, 41030.61it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  29%|██▉       | 196991/677372 [00:04<00:11, 40725.99it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  30%|██▉       | 203135/677372 [00:04<00:10, 44258.01it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  31%|███       | 208255/677372 [00:05<00:10, 44771.06it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  32%|███▏      | 213375/677372 [00:05<00:11, 42159.75it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  32%|███▏      | 218495/677372 [00:05<00:11, 40310.27it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  33%|███▎      | 223615/677372 [00:05<00:11, 39595.65it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  34%|███▍      | 228735/677372 [00:05<00:10, 41144.04it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  35%|███▍      | 233855/677372 [00:05<00:10, 41522.67it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  35%|███▌      | 238975/677372 [00:05<00:11, 37016.40it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  36%|███▌      | 243071/677372 [00:05<00:11, 37395.72it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  37%|███▋      | 248191/677372 [00:06<00:10, 39993.10it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  37%|███▋      | 253311/677372 [00:06<00:10, 40531.44it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  38%|███▊      | 258431/677372 [00:06<00:09, 42137.60it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  39%|███▉      | 263551/677372 [00:06<00:09, 43783.53it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  40%|███▉      | 268671/677372 [00:06<00:09, 42347.47it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  40%|████      | 273791/677372 [00:06<00:09, 40931.90it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  41%|████      | 278911/677372 [00:06<00:10, 38592.43it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  42%|████▏     | 283007/677372 [00:06<00:10, 38467.98it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  42%|████▏     | 287103/677372 [00:07<00:10, 38182.99it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  43%|████▎     | 291199/677372 [00:07<00:10, 38488.09it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  44%|████▎     | 296319/677372 [00:07<00:09, 40214.91it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  45%|████▍     | 301439/677372 [00:07<00:09, 41184.95it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  45%|████▌     | 306559/677372 [00:07<00:08, 41599.94it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  46%|████▌     | 311679/677372 [00:07<00:08, 41295.27it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  47%|████▋     | 316799/677372 [00:07<00:08, 43073.19it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  48%|████▊     | 321919/677372 [00:07<00:07, 45235.21it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  48%|████▊     | 327039/677372 [00:07<00:07, 44089.39it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  49%|████▉     | 332159/677372 [00:08<00:07, 43674.56it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  50%|████▉     | 337279/677372 [00:08<00:07, 43289.58it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  50%|█████     | 341758/677372 [00:08<00:17, 18905.25it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  51%|█████     | 346878/677372 [00:08<00:14, 22746.22it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  52%|█████▏    | 350974/677372 [00:09<00:12, 25598.13it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  52%|█████▏    | 355070/677372 [00:09<00:11, 28267.98it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  53%|█████▎    | 359166/677372 [00:09<00:10, 30827.74it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  54%|█████▎    | 363262/677372 [00:09<00:10, 31018.15it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  54%|█████▍    | 367358/677372 [00:09<00:09, 31891.07it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  55%|█████▍    | 372478/677372 [00:09<00:08, 35945.64it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  56%|█████▌    | 377598/677372 [00:09<00:07, 38691.87it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  57%|█████▋    | 382718/677372 [00:09<00:07, 38344.77it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  57%|█████▋    | 386814/677372 [00:09<00:07, 37069.64it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  58%|█████▊    | 391934/677372 [00:10<00:07, 39793.94it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  58%|█████▊    | 396030/677372 [00:10<00:07, 38781.53it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  59%|█████▉    | 400126/677372 [00:10<00:07, 37312.41it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  60%|█████▉    | 405246/677372 [00:10<00:06, 39046.62it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  60%|██████    | 409342/677372 [00:10<00:07, 34948.37it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  61%|██████    | 413438/677372 [00:10<00:07, 36431.65it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  62%|██████▏   | 418558/677372 [00:10<00:06, 38015.58it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  62%|██████▏   | 422654/677372 [00:10<00:06, 38458.83it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  63%|██████▎   | 427774/677372 [00:10<00:06, 40096.38it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  64%|██████▍   | 431870/677372 [00:11<00:06, 40247.89it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  65%|██████▍   | 436990/677372 [00:11<00:05, 41378.03it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  65%|██████▌   | 443134/677372 [00:11<00:05, 45000.94it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  66%|██████▌   | 448254/677372 [00:11<00:05, 44948.44it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  67%|██████▋   | 453374/677372 [00:11<00:04, 45362.47it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  68%|██████▊   | 458494/677372 [00:11<00:05, 43158.32it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  68%|██████▊   | 463614/677372 [00:11<00:05, 41807.04it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  69%|██████▉   | 468734/677372 [00:11<00:05, 41091.68it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  70%|██████▉   | 473854/677372 [00:12<00:04, 41489.04it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  71%|███████   | 478974/677372 [00:12<00:04, 42258.79it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  71%|███████▏  | 484094/677372 [00:12<00:04, 41669.06it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  72%|███████▏  | 489214/677372 [00:12<00:04, 41620.03it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  73%|███████▎  | 494334/677372 [00:12<00:04, 41411.69it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  74%|███████▎  | 499454/677372 [00:12<00:04, 42460.16it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  75%|███████▍  | 505598/677372 [00:12<00:03, 45068.75it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  75%|███████▌  | 511101/677372 [00:13<00:07, 23291.59it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  76%|███████▋  | 517245/677372 [00:13<00:05, 28893.57it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  77%|███████▋  | 523389/677372 [00:13<00:04, 34403.56it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  78%|███████▊  | 530557/677372 [00:13<00:03, 40503.54it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  79%|███████▉  | 536701/677372 [00:13<00:03, 44781.61it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  80%|████████  | 544893/677372 [00:13<00:02, 52193.04it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  82%|████████▏ | 553085/677372 [00:13<00:02, 57729.85it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  83%|████████▎ | 560253/677372 [00:14<00:01, 59701.88it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  84%|████████▍ | 567421/677372 [00:14<00:01, 59718.04it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  85%|████████▍ | 575613/677372 [00:14<00:01, 59122.91it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  86%|████████▌ | 582781/677372 [00:14<00:01, 60715.28it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  87%|████████▋ | 589949/677372 [00:14<00:01, 60702.63it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  88%|████████▊ | 597117/677372 [00:14<00:01, 50700.15it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  89%|████████▉ | 604285/677372 [00:14<00:01, 54802.35it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  90%|█████████ | 611453/677372 [00:14<00:01, 58510.15it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  91%|█████████▏| 618621/677372 [00:15<00:00, 61859.14it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  92%|█████████▏| 625789/677372 [00:15<00:00, 62551.17it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  93%|█████████▎| 632957/677372 [00:15<00:00, 63682.04it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  95%|█████████▍| 640125/677372 [00:15<00:00, 63939.31it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  96%|█████████▌| 647293/677372 [00:15<00:00, 65756.06it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  97%|█████████▋| 654461/677372 [00:15<00:00, 66681.87it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  98%|█████████▊| 661629/677372 [00:15<00:00, 65093.47it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating:  99%|█████████▊| 668797/677372 [00:15<00:00, 63769.17it/s]\u001B[A\u001B[A\n",
      "\n",
      "Evaluating: 100%|██████████| 677372/677372 [00:16<00:00, 42025.75it/s]\u001B[A\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03, Train: 0.5891, Val: 0.5678, Test: 0.5119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/90941 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 04:   0%|          | 0/90941 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 04:   1%|          | 1024/90941 [00:02<02:57, 507.53it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 04:   2%|▏         | 2048/90941 [00:03<02:14, 660.51it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 04:   3%|▎         | 3072/90941 [00:04<01:57, 746.50it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 04:   5%|▍         | 4096/90941 [00:06<02:28, 584.88it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 04:   6%|▌         | 5120/90941 [00:08<02:38, 540.28it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 04:   7%|▋         | 6144/90941 [00:10<02:39, 533.12it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 04:   8%|▊         | 7168/90941 [00:12<02:32, 548.37it/s]\u001B[A\u001B[A\n",
      "\n",
      "Epoch 04:   9%|▉         | 8192/90941 [00:13<02:13, 618.56it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_35351/170125508.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0mbest_val_acc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfinal_test_acc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m6\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m     \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0macc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m     \u001B[0mtrain_acc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_acc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_acc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'Epoch {epoch:02d}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, '\u001B[0m\u001B[0;34mf'Test: {test_acc:.4f}'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_35351/1748007145.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(epoch)\u001B[0m\n\u001B[1;32m    316\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 318\u001B[0;31m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mn_id\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0madjs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    319\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnll_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mn_id\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    320\u001B[0m         \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1195\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_35351/1748007145.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x, adjs)\u001B[0m\n\u001B[1;32m    153\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0medge_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0madjs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    154\u001B[0m             \u001B[0mx_target\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m  \u001B[0;31m# Target nodes are always placed first.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 155\u001B[0;31m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_target\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0medge_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    156\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mi\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_layers\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m                 \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1195\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/nn/conv/sage_conv.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x, edge_index, size)\u001B[0m\n\u001B[1;32m     83\u001B[0m         \u001B[0mx_r\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     84\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mroot_weight\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mx_r\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 85\u001B[0;31m             \u001B[0mout\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlin_r\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_r\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     86\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     87\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnormalize\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1195\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/nn/dense/linear.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    116\u001B[0m             \u001B[0mx\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mThe\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    117\u001B[0m         \"\"\"\n\u001B[0;32m--> 118\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    119\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    120\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "mlpinit_losses = []\n",
    "mlpinit_test_accs = []\n",
    "\n",
    "model.load_state_dict(torch.load( f'./model_mlpinit.pt'  ))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay = 0.0)\n",
    "\n",
    "best_val_acc = final_test_acc = 0\n",
    "for epoch in range(1, 6):\n",
    "    loss, acc = train(epoch)\n",
    "    train_acc, val_acc, test_acc = test()\n",
    "    print(f'Epoch {epoch:02d}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, 'f'Test: {test_acc:.4f}')\n",
    "    wandb.log({\"loss\": loss, \"acc\": test_acc})\n",
    "    mlpinit_losses.append(loss)\n",
    "    mlpinit_test_accs.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x216 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=range( 0, 3 )\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "ax1.plot(x, random_losses[:3], label='random')\n",
    "ax1.plot(x, mlpinit_losses, label='mlpinit')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2.plot(x, random_test_accs[:3], label='random')\n",
    "ax2.plot(x, mlpinit_test_accs, label='mlpinit')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.set_ylabel('accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_speedup(random_accs, mlpinit_accs):\n",
    "    best_speedup = 0\n",
    "    best_line = 0\n",
    "    for value in np.linspace(start=0, stop=1, num=10):\n",
    "        first_achieved = 0\n",
    "        second_achieved = 1000\n",
    "        for j in range(len(random_accs)):\n",
    "            if random_accs[j] > value:\n",
    "                first_achieved = j\n",
    "                break\n",
    "        first_achieved += 1\n",
    "        for j in range(len(mlpinit_accs)):\n",
    "            if mlpinit_accs[j] > value:\n",
    "                second_achieved = j\n",
    "                break\n",
    "        second_achieved += 1\n",
    "        if second_achieved == 0:\n",
    "            best_speedup = 0\n",
    "        else:\n",
    "            if best_speedup < first_achieved/second_achieved:\n",
    "                best_line = value\n",
    "                best_speedup = first_achieved/second_achieved\n",
    "    return best_line, best_speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "best_line, best_speedup = find_best_speedup(random_test_accs[:3], mlpinit_test_accs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "best_line, best_speedup = find_best_speedup(a1, a2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table = wandb.Table(columns=[\"best_line\", \"best_speedup\"], data=[[best_line, best_speedup]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "wandb.log({\"table\": my_table})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = [0.1, 0.2, 0.4]\n",
    "a2 = [0.4, 0.4, 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
